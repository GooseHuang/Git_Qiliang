{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLet's Check Zero one prediction problem\\n\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's Check Zero one prediction problem\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "h1 = lambda x: display(Markdown('# '+str(x)))\n",
    "h3 = lambda x: display(Markdown('### '+str(x)))\n",
    "h4 = lambda x: display(Markdown('#### '+ (str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "h5 = lambda x: display(Markdown('##### '+ (str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "bl = lambda x: display(Markdown('##### <font color=\"blue\"> %s </font>'%(str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "rd = lambda x: display(Markdown('##### <font color=\"red\"> %s </font>'%(str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "rd1 = lambda x: display(Markdown('# <font color=\"red\"> %s </font>'%(str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "gra = lambda x: display(Markdown('##### <font color=\"gray\"> %s </font>'%(str(x).replace(' ','&nbsp;') if str(x) else 'None')))\n",
    "itc = lambda x: display(Markdown('***'+str(x.strip()) + '***' ))\n",
    "pl = lambda: print('\\n'+'#'*100 + '\\n')\n",
    "pl2 = lambda: print('\\n'+'='*100 + '\\n')\n",
    "pls = lambda: print('\\n'+'#'*50 +' Start '+'#'*50 + '\\n')\n",
    "pn = lambda x=5: print('\\n'*x)\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Made Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://144.34.140.210:8579/notebooks/Git_Qiliang/ML_ANN_Gradiant_Decent/Backpropagation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "bp = pdb.set_trace\n",
    "\n",
    "import random\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Direct\n",
    "# def relu(x):\n",
    "#     return x\n",
    "# activation_func = np.vectorize(relu)  \n",
    "\n",
    "         \n",
    "# def derivative(x):\n",
    "#     return 1\n",
    "# derivative_func = np.vectorize(derivative)   \n",
    "\n",
    "\n",
    "# Relu\n",
    "def relu(x):\n",
    "    if x >0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "activation_func = np.vectorize(relu)  \n",
    "\n",
    "         \n",
    "def derivative(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "derivative_func = np.vectorize(derivative)   \n",
    "\n",
    "\n",
    "# # Sigmoid\n",
    "# def relu(x):\n",
    "#     if x<-100:\n",
    "#         return 0\n",
    "#     elif x>100:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         y = 1/(1+np.exp(-x))\n",
    "#         return y\n",
    "# activation_func = np.vectorize(relu)  \n",
    "\n",
    "         \n",
    "# def derivative(x):\n",
    "#     return x*(1-x)\n",
    "# derivative_func = np.vectorize(derivative)   \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# def relu(x):\n",
    "#     if x>0:\n",
    "#         if x<5:\n",
    "#             return x\n",
    "#         else:\n",
    "#             return 5\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "\n",
    "# activation_func = np.vectorize(relu)  \n",
    "# # activation_func = np.vectorize(lambda x: x) \n",
    "         \n",
    "# def derivative(x):\n",
    "#     if x>0:\n",
    "#             return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "# #         return -1\n",
    "# #         return 1\n",
    "# derivative_func = np.vectorize(derivative)   \n",
    "    \n",
    "    \n",
    "class Weight:\n",
    "    def __init__(self,m,n):\n",
    "        self.sigma = 0.2# 0.1 # 0.3 #0.2\n",
    "        self.mu = 0 #0.5\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.val = self.sigma * np.random.randn(m,n) + self.mu\n",
    "#         self.normalize()\n",
    "        \n",
    "    def normalize(self):\n",
    "        self.val = self.val/self.val.sum()\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self,n,id=None,output_ind=False):\n",
    "        self.val = None\n",
    "        self.id = id\n",
    "        self.input_weight = None\n",
    "        self.output_weight = None\n",
    "        self.pre_layer = None\n",
    "        self.next_layer = None\n",
    "        self.n = n\n",
    "        self.delta_weight = None\n",
    "        self.output_ind = output_ind\n",
    "        \n",
    "        \n",
    "    def full_connect(self,other):\n",
    "        m = self.n\n",
    "        n = other.n\n",
    "        weight = Weight(m,n)\n",
    "        self.output_weight = weight\n",
    "        other.input_weight = weight\n",
    "        \n",
    "        self.next_layer = other\n",
    "        other.pre_layer = self\n",
    "    \n",
    "    def stats(self):\n",
    "        print(\"n:\",self.n)\n",
    "        if self.output_weight:\n",
    "            print('Weight:',self.output_weight.val.shape)\n",
    "        print()\n",
    "            \n",
    "    def pull_in(self,input_list):\n",
    "        self.val = np.array([input_list,])\n",
    "#         self.val = self.val/self.val.sum()\n",
    "            \n",
    "    def forwarding(self):\n",
    "#         print(self.id,'forwarding')\n",
    "        val = self.val.dot(self.output_weight.val)\n",
    "        try:\n",
    "            if self.next_layer:\n",
    "                if not self.next_layer.output_ind:\n",
    "                    self.next_layer.val = activation_func(val)   \n",
    "                else:\n",
    "                    self.next_layer.val = val \n",
    "        except:\n",
    "#             bp()\n",
    "            raise\n",
    "        \n",
    "    def backwarding(self, error_term, learning_rate):\n",
    "#         print(self.id,'backwarding')\n",
    "        pre = self.pre_layer\n",
    "        K1 = pre.output_weight.val\n",
    "#         print(K1.shape)\n",
    "        while(pre.pre_layer):\n",
    "            pre = pre.pre_layer\n",
    "            K1 = pre.output_weight.val.dot(K1)\n",
    "            \n",
    "        K1 = pre.val.dot(K1)\n",
    "#         print('K1:',K1.shape)\n",
    "\n",
    "\n",
    "        next_layer = self.next_layer\n",
    "        if next_layer.output_weight:\n",
    "            K2 = next_layer.output_weight.val\n",
    "            while(next_layer.next_layer.output_weight):\n",
    "                next_layer = next_layer.next_layer\n",
    "                K2 = K2.dot(next_layer.output_weight.val) \n",
    "#             print(\"K2:\",K2.shape)\n",
    "        else:\n",
    "            K2 = np.array([[1]])\n",
    "                   \n",
    "        derivative = (K1.T*self.val.T).dot(K2.T)\n",
    "#         derivative = K1.T.dot(K2.T)\n",
    "#         bp()\n",
    "    \n",
    "        if not self.output_ind:\n",
    "            K3 = derivative_func(self.val)\n",
    "#             bp()\n",
    "            derivative = derivative*K3.T\n",
    "#         bp()\n",
    "#         print(\"Derivative:\",derivative.shape)\n",
    "#         return derivative\n",
    "\n",
    "#         derivative = derivative/derivative.sum()\n",
    "    \n",
    "        delta_weight = learning_rate*(-1)*(error_term)*derivative\n",
    "#         bp()\n",
    "#         print('delta_weight:',delta_weight)\n",
    "        if type(self.delta_weight)!=type(None):\n",
    "            self.delta_weight += delta_weight\n",
    "        else:\n",
    "            self.delta_weight = delta_weight\n",
    "    \n",
    "    def update_weights(self):\n",
    "        if type(self.delta_weight)!=type(None):\n",
    "            self.output_weight.val += self.delta_weight\n",
    "            self.delta_weight = None\n",
    "    \n",
    "class Network:\n",
    "    def __init__(self,input_layer,output_layer):\n",
    "        self.input_layer = input_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.learning_rate = 0.01\n",
    "        \n",
    "    def set_learning_rate(self,rate):\n",
    "        self.learning_rate = rate\n",
    "        \n",
    "              \n",
    "    def batch_forwarding(self):\n",
    "        cur = self.input_layer\n",
    "        while(cur.next_layer):\n",
    "            cur.forwarding()\n",
    "            cur = cur.next_layer\n",
    "             \n",
    "    def get_error_term(self,ground_truth_list):      \n",
    "        error = self.output_layer.val-ground_truth_list\n",
    "        return error\n",
    "    \n",
    "    def batch_backwarding(self, error_term):\n",
    "        cur = self.input_layer.next_layer\n",
    "        while(cur and cur.output_weight):\n",
    "            cur.backwarding(error_term, self.learning_rate)\n",
    "            cur = cur.next_layer\n",
    "            \n",
    "    def one_train(self,x,y):\n",
    "        input_layer.pull_in(x)\n",
    "        self.batch_forwarding()\n",
    "        error_term = self.get_error_term(y)\n",
    "        self.batch_backwarding(error_term)\n",
    "        \n",
    "        \n",
    "    def batch_update_weights(self):\n",
    "        cur = self.input_layer.next_layer\n",
    "        while(cur and cur.output_weight):\n",
    "            cur.update_weights() \n",
    "            cur = cur.next_layer\n",
    "\n",
    "    def batch_train(self,X,Y,batch_size=20):\n",
    "        i=0\n",
    "        for i,(x,y) in enumerate(zip(X,Y)):\n",
    "            self.one_train(x,y)\n",
    "            if i%batch_size==0:\n",
    "                self.batch_update_weights()\n",
    "        self.batch_update_weights()\n",
    "        \n",
    "        \n",
    "    def predict(self,x):\n",
    "        input_layer.pull_in(x)\n",
    "        self.batch_forwarding()\n",
    "        return self.output_layer.val\n",
    "    \n",
    "    \n",
    "#     def save(self,model_dir='./model.json'):\n",
    "#         res = []\n",
    "#         cur = self.input_layer\n",
    "#         while(cur.output_weight):\n",
    "#             res.append(cur)\n",
    "         \n",
    "#     def load(self,model_dir='./model.json')\n",
    "#         pass\n",
    "\n",
    "\n",
    "\n",
    "# # Networks\n",
    "# input_layer = Layer(10,'in')\n",
    "# l1 = Layer(10,'l1')\n",
    "# l2 = Layer(50,'l2')\n",
    "# l3 = Layer(50,'l3')\n",
    "# l4 = Layer(10,'l4')\n",
    "# output_layer = Layer(1,'out')\n",
    "\n",
    "\n",
    "# input_layer.full_connect(l1)\n",
    "# l1.full_connect(l2)\n",
    "# l2.full_connect(l3)\n",
    "# l3.full_connect(l4)\n",
    "# l4.full_connect(output_layer)\n",
    "\n",
    "# x = random.choices(range(100), k=10)\n",
    "\n",
    "# print(x)\n",
    "# y = np.array([[1]])\n",
    "\n",
    "# nk = Network(input_layer,output_layer)\n",
    "# nk.one_train(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n最简单和最直接的方法是什么\\n\\n看起来不行\\n\\n如何保证每次都有进步呢？  这种简单的信息是如何被学到的呢？\\n\\n这是一个超级不稳定的系统\\n\\n\\n产生合理的顿感系数\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "最简单和最直接的方法是什么\n",
    "\n",
    "看起来不行\n",
    "\n",
    "如何保证每次都有进步呢？  这种简单的信息是如何被学到的呢？\n",
    "\n",
    "这是一个超级不稳定的系统\n",
    "\n",
    "\n",
    "产生合理的顿感系数\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Networks\n",
    "# input_layer = Layer(10,'in')\n",
    "# l1 = Layer(10,'l1')\n",
    "# l2 = Layer(50,'l2')\n",
    "# l3 = Layer(50,'l3')\n",
    "# l4 = Layer(10,'l4')\n",
    "# output_layer = Layer(1,'out',output_ind=True)\n",
    "\n",
    "# input_layer.full_connect(l1)\n",
    "# l1.full_connect(l2)\n",
    "# l2.full_connect(l3)\n",
    "# l3.full_connect(l4)\n",
    "# l4.full_connect(output_layer)\n",
    "\n",
    "\n",
    "# # Networks\n",
    "# input_layer = Layer(10,'in')\n",
    "# l1 = Layer(10,'l1')\n",
    "# l2 = Layer(50,'l2')\n",
    "# l2_5 = Layer(50,'l2.5')\n",
    "# l3 = Layer(50,'l3')\n",
    "# l4 = Layer(10,'l4')\n",
    "# output_layer = Layer(1,'out',output_ind=True)\n",
    "\n",
    "# input_layer.full_connect(l1)\n",
    "# l1.full_connect(l2)\n",
    "# l2.full_connect(l2_5)\n",
    "# l2_5.full_connect(l3)\n",
    "# l3.full_connect(l4)\n",
    "# l4.full_connect(output_layer)\n",
    "\n",
    "# # Networks\n",
    "# input_layer = Layer(1,'in')\n",
    "# l1 = Layer(10,'l1')\n",
    "# l2 = Layer(50,'l2')\n",
    "# l3 = Layer(50,'l3')\n",
    "# l4 = Layer(50,'l4')\n",
    "# output_layer = Layer(1,'out',output_ind=True)\n",
    "\n",
    "# input_layer.full_connect(l1)\n",
    "# l1.full_connect(l2)\n",
    "# l2.full_connect(l3)\n",
    "# l3.full_connect(l4)\n",
    "# l4.full_connect(output_layer)\n",
    "\n",
    "\n",
    "\n",
    "# Networks\n",
    "input_layer = Layer(1,'in')\n",
    "l1 = Layer(10,'l1')\n",
    "l2 = Layer(10,'l2')\n",
    "output_layer = Layer(1,'out',output_ind=True)\n",
    "\n",
    "input_layer.full_connect(l1)\n",
    "l1.full_connect(l2)\n",
    "l2.full_connect(output_layer)\n",
    "\n",
    "nk = Network(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "# for i in range(1):\n",
    "# for i in range(10):\n",
    "# for i in range(100):\n",
    "# for i in range(500):\n",
    "# for i in range(1000):\n",
    "for i in range(10000):\n",
    "# for i in range(100000):\n",
    "# for i in range(1000000):\n",
    "# for i in range(5000000):\n",
    "# for i in range(15000000):\n",
    "# for i in range(50000000):\n",
    "#     x = np.array(random.choices(range(100), k=10))\n",
    "    x = np.array([np.random.rand(),])\n",
    "    if x>0.5:\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "        \n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nk.set_learning_rate(0.0000000000001)\n",
    "# nk.set_learning_rate(0.00000001)\n",
    "# nk.set_learning_rate(0.00001)\n",
    "# nk.set_learning_rate(0.0001)\n",
    "# nk.set_learning_rate(0.001)\n",
    "nk.set_learning_rate(0.01)\n",
    "# nk.set_learning_rate(0.1)\n",
    "# nk.set_learning_rate(1)\n",
    "# nk.set_learning_rate(2)\n",
    "nk.batch_train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.22755825]\n",
      "y_real: 0\n",
      "y_predict: [[0.]]\n",
      "rate: [[inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "x = np.array([np.random.rand(),])\n",
    "if x>0.5:\n",
    "    y=1\n",
    "else:\n",
    "    y=0\n",
    "y_predict = nk.predict(x)\n",
    "\n",
    "print('x:',x)\n",
    "print('y_real:',y)\n",
    "print('y_predict:',y_predict)\n",
    "print('rate:',x/y_predict)\n",
    "\n",
    "# print('l1:\\n',l1.val)\n",
    "# print('l2:\\n',l2.val)\n",
    "# print('l3:\\n',l3.val)\n",
    "# print('l4:\\n',l4.val)\n",
    "# pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "非常成功的正确收敛了\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "res = np.array([x[0] for x in X])\n",
    "plt.hist(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5          0.7083333333333334\n",
      "0.51          0.7042\n",
      "0.52          0.7001333333333334\n",
      "0.53          0.6961333333333334\n",
      "0.54          0.6922\n",
      "0.55          0.6883333333333334\n",
      "0.56          0.6845333333333333\n",
      "0.57          0.6808\n",
      "0.58          0.6771333333333333\n",
      "0.59          0.6735333333333333\n",
      "0.6          0.6699999999999999\n",
      "0.61          0.6665333333333333\n",
      "0.62          0.6631333333333332\n",
      "0.63          0.6598\n",
      "0.64          0.6565333333333333\n",
      "0.65          0.6533333333333332\n",
      "0.66          0.6502\n",
      "0.67          0.6471333333333332\n",
      "0.68          0.6441333333333333\n",
      "0.69          0.6411999999999999\n",
      "0.7          0.6383333333333333\n",
      "0.71          0.6355333333333333\n",
      "0.72          0.6327999999999999\n",
      "0.73          0.6301333333333332\n",
      "0.74          0.6275333333333333\n",
      "0.75          0.625\n",
      "0.76          0.6225333333333333\n",
      "0.77          0.6201333333333333\n",
      "0.78          0.6177999999999999\n",
      "0.79          0.6155333333333334\n",
      "0.8          0.6133333333333333\n",
      "0.81          0.6111999999999999\n",
      "0.82          0.6091333333333333\n",
      "0.83          0.6071333333333333\n",
      "0.84          0.6052\n",
      "0.85          0.6033333333333332\n",
      "0.86          0.6015333333333333\n",
      "0.87          0.5998\n",
      "0.88          0.5981333333333333\n",
      "0.89          0.5965333333333332\n",
      "0.9          0.5949999999999999\n",
      "0.91          0.5935333333333332\n",
      "0.92          0.5921333333333333\n",
      "0.93          0.5908\n",
      "0.94          0.5895333333333332\n",
      "0.95          0.5883333333333333\n",
      "0.96          0.5871999999999998\n",
      "0.97          0.5861333333333333\n",
      "0.98          0.5851333333333333\n",
      "0.99          0.5841999999999999\n",
      "1.0          0.5833333333333334\n",
      "1.01          0.5825333333333333\n",
      "1.02          0.5818\n",
      "1.03          0.5811333333333333\n",
      "1.04          0.5805333333333332\n",
      "1.05          0.58\n",
      "1.06          0.5795333333333333\n",
      "1.07          0.5791333333333334\n",
      "1.08          0.5788000000000001\n",
      "1.09          0.5785333333333333\n",
      "1.1          0.5783333333333333\n",
      "1.11          0.5781999999999999\n",
      "1.12          0.5781333333333333\n",
      "1.13          0.5781333333333333\n",
      "1.14          0.5781999999999999\n",
      "1.15          0.5783333333333334\n",
      "1.16          0.5785333333333335\n",
      "1.17          0.5788000000000001\n",
      "1.18          0.5791333333333334\n",
      "1.19          0.5795333333333333\n",
      "1.2          0.58\n",
      "1.21          0.5805333333333333\n",
      "1.22          0.5811333333333334\n",
      "1.23          0.5818000000000001\n",
      "1.24          0.5825333333333335\n",
      "1.25          0.5833333333333335\n",
      "1.26          0.5841999999999999\n",
      "1.27          0.5851333333333334\n",
      "1.28          0.5861333333333334\n",
      "1.29          0.5872\n",
      "1.3          0.5883333333333335\n",
      "1.31          0.5895333333333335\n",
      "1.32          0.5908000000000001\n",
      "1.33          0.5921333333333335\n",
      "1.34          0.5935333333333336\n",
      "1.35          0.5950000000000001\n",
      "1.36          0.5965333333333335\n",
      "1.37          0.5981333333333334\n",
      "1.38          0.5998000000000001\n",
      "1.39          0.6015333333333335\n",
      "1.4          0.6033333333333335\n",
      "1.41          0.6052000000000002\n",
      "1.42          0.6071333333333334\n",
      "1.43          0.6091333333333334\n",
      "1.44          0.6112000000000002\n",
      "1.45          0.6133333333333334\n",
      "1.46          0.6155333333333335\n",
      "1.47          0.6178000000000002\n",
      "1.48          0.6201333333333335\n",
      "1.49          0.6225333333333336\n"
     ]
    }
   ],
   "source": [
    "for x in np.arange(0.5,1.5,0.01):\n",
    "    res = (x*x-2.25*x+3)/3\n",
    "    print(round(x,2),'        ',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4958, 1: 5042})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2291.9292073874544"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "res = nk.predict(X)\n",
    "res = res[0]\n",
    "res = res.T\n",
    "res = res[0]\n",
    "res.shape\n",
    "# res\n",
    "res = list(map(abs,Y - res))\n",
    "sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484.8141326108725"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "rate = 1\n",
    "Y_test = np.array([x[0]/rate for x in X])\n",
    "res = list(map(abs,Y - Y_test))\n",
    "sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5          4914.039458404094\n",
      "0.51          4721.0775306032865\n",
      "0.52          4539.575339612965\n",
      "0.53          4368.446721136472\n",
      "0.54          4207.144873833657\n",
      "0.55          4055.201714155908\n",
      "0.56          3912.195423188093\n",
      "0.57          3777.9638506788197\n",
      "0.58          3652.083443954314\n",
      "0.59          3534.326734162998\n",
      "0.6          3423.937524540013\n",
      "0.61          3320.133032475564\n",
      "0.62          3222.9733181002393\n",
      "0.63          3132.415700090723\n",
      "0.64          3048.20279558077\n",
      "0.65          2969.605208067404\n",
      "0.66          2897.212650990355\n",
      "0.67          2830.10332257224\n",
      "0.68          2768.26557100505\n",
      "0.69          2711.2840395398093\n",
      "0.7          2658.5952237840856\n",
      "0.71          2610.14843865609\n",
      "0.72          2565.520931384852\n",
      "0.73          2524.9686701976216\n",
      "0.74          2487.8996679472953\n",
      "0.75          2454.38715137073\n",
      "0.76          2424.398300528444\n",
      "0.77          2397.8741147476967\n",
      "0.78          2374.7141211177604\n",
      "0.79          2354.7091027900597\n",
      "0.8          2337.5965475984212\n",
      "0.81          2323.1232618422937\n",
      "0.82          2311.3987315256363\n",
      "0.83          2302.4486897762654\n",
      "0.84          2296.3976860595403\n",
      "0.85          2292.8350247767444\n",
      "0.86          2291.6771298477506\n",
      "0.87          2292.9738866097605\n",
      "0.88          2296.67847464759\n",
      "0.89          2302.447627943154\n",
      "0.9          2310.2508185153993\n",
      "0.91          2319.935532774179\n",
      "0.92          2331.322376487614\n",
      "0.93          2344.42694934146\n",
      "0.94          2359.4233976662904\n",
      "0.95          2376.25556365618\n",
      "0.96          2394.742761983852\n",
      "0.97          2414.9299524508306\n",
      "0.98          2436.5850154728705\n",
      "0.99          2459.957890803765\n",
      "1.0          2484.8141326108744\n",
      "1.01          2510.132804565238\n",
      "1.02          2534.955031971467\n",
      "1.03          2559.295274379489\n",
      "1.04          2583.1674352027653\n",
      "1.05          2606.584888200845\n",
      "1.06          2629.560502463083\n",
      "1.07          2652.1066659914723\n",
      "1.08          2674.2353079730324\n",
      "1.09          2695.957919826502\n",
      "1.1          2717.2855751007996\n",
      "1.11          2738.228948298093\n",
      "1.12          2758.798332688284\n",
      "1.13          2779.0036571777778\n",
      "1.14          2798.8545022902517\n",
      "1.15          2818.360115313815\n",
      "1.16          2837.529424664562\n",
      "1.17          2856.3710535135797\n",
      "1.18          2874.8933327210884\n",
      "1.19          2893.104313118386\n",
      "1.2          2911.011777175738\n",
      "1.21          2928.623250091642\n",
      "1.22          2945.9460103367855\n",
      "1.23          2962.9870996836494\n",
      "1.24          2979.75333275072\n",
      "1.25          2996.251306088716\n",
      "1.26          3012.487406834033\n",
      "1.27          3028.467820953456\n",
      "1.28          3044.198541102256\n",
      "1.29          3059.6853741169625\n",
      "1.3          3074.9339481622055\n",
      "1.31          3089.9497195502913\n",
      "1.32          3104.7379792506704\n",
      "1.33          3119.303859105923\n",
      "1.34          3133.652337769327\n",
      "1.35          3147.788246378429\n",
      "1.36          3161.716273978586\n",
      "1.37          3175.440972708663\n",
      "1.38          3188.9667627615117\n",
      "1.39          3202.2979371301267\n",
      "1.4          3215.4386661506037\n",
      "1.41          3228.3930018517044\n",
      "1.42          3241.1648821203416\n",
      "1.43          3253.75813469292\n",
      "1.44          3266.1764809797596\n",
      "1.45          3278.4235397316443\n",
      "1.46          3290.502830555394\n",
      "1.47          3302.4177772863104\n",
      "1.48          3314.171711223573\n",
      "1.49          3325.767874235502\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "for rate in np.arange(0.5,1.5,0.01):\n",
    "    Y_test = np.array([x[0]/rate for x in X])\n",
    "    res = list(map(abs,Y - Y_test))\n",
    "    print(round(rate,2),'        ',sum(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51142119.52861147"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(abs,Y - nk.predict(X)))[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1764705882352942"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n尝试下非0、1，看是否会收敛   可以收敛\\n\\n需要有偏置项？\\n\\n使用更简单的网络试试\\n\\n\\n也许可以储备多种终端传导方式供选择   \\n\\n有多种结合体？ 不同特性的    如何连接\\n\\n似乎没有学到   但是成功产生收敛了   因为weight叠加加成的影响，学习率变得很重要\\n\\n初始weight的选取似乎影响很大\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "可以很快收敛  anyway\n",
    "\n",
    "\n",
    "结果比例反直觉的\n",
    "\n",
    "\n",
    "这里01收敛的也非常快\n",
    "\n",
    "尝试下非0、1，看是否会收敛   可以收敛\n",
    "\n",
    "需要有偏置项？\n",
    "\n",
    "使用更简单的网络试试\n",
    "\n",
    "\n",
    "也许可以储备多种终端传导方式供选择   \n",
    "\n",
    "有多种结合体？ 不同特性的    如何连接\n",
    "\n",
    "似乎没有学到   但是成功产生收敛了   因为weight叠加加成的影响，学习率变得很重要\n",
    "\n",
    "初始weight的选取似乎影响很大\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02216518]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03918611, -0.12281529,  0.06792611, -0.11755786,  0.07642432,\n",
       "        -0.01832774, -0.17595614,  0.2328283 , -0.21609369,  0.11523112],\n",
       "       [ 0.2456928 , -0.20495374, -0.32028993, -0.17907246, -0.07006069,\n",
       "        -0.11699164, -0.29705128, -0.04706611,  0.01999039, -0.02176801],\n",
       "       [ 0.16685262,  0.00895923,  0.02610799, -0.07146169,  0.17526497,\n",
       "         0.03107043,  0.11720641, -0.1619822 ,  0.02788863,  0.31111499],\n",
       "       [ 0.05112299, -0.44011925,  0.04673092,  0.0121415 ,  0.07461036,\n",
       "        -0.06868935,  0.05117017,  0.10363816,  0.14199112, -0.18552199],\n",
       "       [-0.01560973, -0.22779106, -0.03364152,  0.10041211,  0.12835711,\n",
       "        -0.01459869,  0.21032109,  0.24286589,  0.19904107,  0.26987371],\n",
       "       [ 0.44550658,  0.16231856, -0.25511153, -0.16180249,  0.1098703 ,\n",
       "         0.23058926,  0.23459169, -0.12243993, -0.02188998, -0.16650809],\n",
       "       [-0.0093137 ,  0.07253971,  0.19666683,  0.20090088,  0.23301138,\n",
       "         0.26398441,  0.28539696,  0.03460594, -0.00572479,  0.12821394],\n",
       "       [ 0.01027073,  0.20067267, -0.23231442,  0.15897503,  0.43952055,\n",
       "         0.24593497,  0.18065804,  0.32950825, -0.03065221,  0.10033901],\n",
       "       [-0.13411109,  0.1046537 , -0.27217128, -0.30394292,  0.40279629,\n",
       "         0.3745677 ,  0.11068691, -0.40371144,  0.11660117,  0.0975465 ],\n",
       "       [ 0.00326199, -0.12843562, -0.21809216,  0.07681092,  0.05052778,\n",
       "        -0.02231373,  0.06926914,  0.04768975, -0.07480289, -0.14050166]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.output_weight.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0050909 ,  0.00388702, -0.0030081 ,  0.00356545, -0.0029844 ,\n",
       "         0.00684015,  0.00288455, -0.00623966, -0.00034426, -0.002952  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44837445],\n",
       "       [-0.05647708],\n",
       "       [-0.07714227],\n",
       "       [ 0.05928375],\n",
       "       [ 0.01750058],\n",
       "       [ 0.31027612],\n",
       "       [ 0.37022722],\n",
       "       [ 0.19837864],\n",
       "       [-0.12138778],\n",
       "       [ 0.00243319]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.output_weight.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0034754 , -0.00192774,  0.00029867, -0.00297726, -0.00213414,\n",
       "        -0.00010175, -0.00179017, -0.00166118, -0.00098836, -0.00291473]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3872\\3230013897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'l3' is not defined"
     ]
    }
   ],
   "source": [
    "l3.output_weight.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [212]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ml3\u001b[49m\u001b[38;5;241m.\u001b[39mval\n",
      "\u001b[1;31mNameError\u001b[0m: name 'l3' is not defined"
     ]
    }
   ],
   "source": [
    "l3.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59472918],\n",
       "       [-0.24441027],\n",
       "       [ 0.62609755],\n",
       "       [-0.10691708],\n",
       "       [ 0.30003725],\n",
       "       [ 0.18347305],\n",
       "       [ 0.18243542],\n",
       "       [ 0.16239599],\n",
       "       [-0.22661432],\n",
       "       [ 0.02297569],\n",
       "       [ 0.69880413],\n",
       "       [ 0.56031021],\n",
       "       [ 0.08163068],\n",
       "       [ 0.04369627],\n",
       "       [ 0.45100922],\n",
       "       [ 0.18293961],\n",
       "       [-0.0116464 ],\n",
       "       [-0.55731291],\n",
       "       [ 0.2540942 ],\n",
       "       [ 0.09632412],\n",
       "       [ 0.50653305],\n",
       "       [-0.28051569],\n",
       "       [ 0.0069488 ],\n",
       "       [ 0.10843931],\n",
       "       [ 0.03860016],\n",
       "       [ 0.47657341],\n",
       "       [-0.08330561],\n",
       "       [-0.17609592],\n",
       "       [-0.05295108],\n",
       "       [-0.25617296],\n",
       "       [ 0.55676044],\n",
       "       [-0.07676087],\n",
       "       [-0.07558063],\n",
       "       [-0.01314843],\n",
       "       [-0.23466799],\n",
       "       [ 0.41508251],\n",
       "       [-0.25120104],\n",
       "       [ 0.01402803],\n",
       "       [-0.13615577],\n",
       "       [ 0.01784295],\n",
       "       [ 0.30223832],\n",
       "       [-0.57344112],\n",
       "       [ 0.36587298],\n",
       "       [-0.06703676],\n",
       "       [ 0.10811401],\n",
       "       [ 0.33392039],\n",
       "       [-0.22295409],\n",
       "       [ 0.16608182],\n",
       "       [-0.29362472],\n",
       "       [-0.12071313]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4.output_weight.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95236050e-01,  9.57827551e-02,  1.54415396e-02,\n",
       "         1.90973974e-01, -1.90742693e-01,  1.40109049e-01,\n",
       "         1.30953365e-01,  1.74646112e-01,  5.09469716e-02,\n",
       "        -6.48411898e-02, -3.11482187e-01,  1.79225692e-01,\n",
       "        -1.63757917e-04, -1.08607787e-01,  1.28668819e-02,\n",
       "         1.73872095e-01,  8.19001427e-03,  1.69637233e-01,\n",
       "         7.29088121e-03, -3.03357257e-01, -4.05746328e-01,\n",
       "         1.66482086e-01, -6.84090987e-02,  8.80046900e-02,\n",
       "         1.04884739e-01,  1.17373835e-01,  1.73952463e-02,\n",
       "        -7.02409628e-02, -1.74645586e-01, -1.15991539e-01,\n",
       "        -3.60247616e-02, -1.36674438e-02,  3.14791959e-01,\n",
       "         8.52311187e-02,  4.59278015e-02,  2.57992622e-02,\n",
       "         4.82661233e-02,  3.51150368e-03, -6.80787839e-02,\n",
       "         1.16164178e-01, -4.16179338e-01,  2.80416144e-03,\n",
       "        -3.33978546e-01,  4.34409281e-02, -2.09042447e-02,\n",
       "        -2.25706641e-01, -3.88800903e-02,  9.62131200e-02,\n",
       "         1.38550807e-01,  2.41214260e-01]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90226704]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9022670437452267"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer.val[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "当前设置非常容易出现参数消失\n",
    "\n",
    "\n",
    "找一种函数可以自动的大变小，小变大\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://app.yinxiang.com/shard/s18/nl/18934792/e81511f4-0b23-48bc-b627-22416bbf9554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
