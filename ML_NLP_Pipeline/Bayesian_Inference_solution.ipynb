{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Mission ##\n",
    "\n",
    "Spam detection is one of the major applications of Machine Learning in the interwebs today. Pretty much all of the major email service providers have spam detection systems built in and automatically classify such mail as 'Junk Mail'. \n",
    "\n",
    "In this mission we will be using the Naive Bayes algorithm to create a model that can classify [dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) SMS messages as spam or not spam, based on the training we give to the model. It is important to have some level of intuition as to what a spammy text message might look like. Usually they have words like 'free', 'win', 'winner', 'cash', 'prize' and the like in them as these texts are designed to catch your eye and in some sense tempt you to open them. Also, spam messages tend to have words written in all capitals and also tend to use a lot of exclamation marks. To the recipient, it is usually pretty straightforward to identify a spam text and our objective here is to train a model to do that for us!\n",
    "\n",
    "Being able to identify spam messages is a binary classification problem as messages are classified as either 'Spam' or 'Not Spam' and nothing else. Also, this is a supervised learning problem, as we will be feeding a labelled dataset into the model, that it can learn from, to make future predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Introduction to the Naive Bayes Theorem ###\n",
    "\n",
    "Bayes theorem is one of the earliest probabilistic inference algorithms developed by Reverend Bayes (which he used to try and infer the existence of God no less) and still performs extremely well for certain use cases. \n",
    "\n",
    "It's best to understand this theorem using an example. Let's say you are a member of the Secret Service and you have been deployed to protect the Democratic presidential nominee during one of his/her campaign speeches. Being a public event that is open to all, your job is not easy and you have to be on the constant lookout for threats. So one place to start is to put a certain threat-factor for each person. So based on the features of an individual, like the age, sex, and other smaller factors like is the person carrying a bag?, does the person look nervous? etc. you can make a judgement call as to if that person is viable threat. \n",
    "\n",
    "If an individual ticks all the boxes up to a level where it crosses a threshold of doubt in your mind, you can take action and remove that person from the vicinity. The Bayes theorem works in the same way as we are computing the probability of an event(a person being a threat) based on the probabilities of certain related events(age, sex, presence of bag or not, nervousness etc. of the person). \n",
    "\n",
    "One thing to consider is the independence of these features amongst each other. For example if a child looks nervous at the event then the likelihood of that person being a threat is not as much as say if it was a grown man who was nervous. To break this down a bit further, here there are two features we are considering, age AND nervousness. Say we look at these features individually, we could design a model that flags ALL persons that are nervous as potential threats. However, it is likely that we will have a lot of false positives as there is a strong chance that minors present at the event will be nervous. Hence by considering the age of a person along with the 'nervousness' feature we would definitely get a more accurate result as to who are potential threats and who aren't. \n",
    "\n",
    "This is the 'Naive' bit of the theorem where it considers each feature to be independant of each other which may not always be the case and hence that can affect the final judgement.\n",
    "\n",
    "In short, the Bayes theorem calculates the probability of a certain event happening(in our case, a message being  spam) based on the joint probabilistic distributions of certain other events(in our case, a message being classified as spam). We will dive into the workings of the Bayes theorem later in the mission, but first, let us understand the data we are going to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1: Understanding our dataset ### \n",
    "\n",
    "\n",
    "We will be using a [dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) from the UCI Machine Learning repository which has a very good collection of datasets for experimental research purposes. The direct data link is [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/).\n",
    "\n",
    "\n",
    " ** Here's a preview of the data: ** \n",
    "\n",
    "<img src=\"images/dqnb.png\" height=\"1242\" width=\"1242\">\n",
    "\n",
    "The columns in the data set are currently not named and as you can see, there are 2 columns. \n",
    "\n",
    "The first column takes two values, 'ham' which signifies that the message is not spam, and 'spam' which signifies that the message is spam. \n",
    "\n",
    "The second column is the text content of the SMS message that is being classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">** Instructions: **\n",
    "* Import the dataset into a pandas dataframe using the read_table method. Because this is a tab separated dataset we will be using '\\t' as the value for the 'sep' argument which specifies this format. \n",
    "* Also, rename the column names by specifying a list ['label, 'sms_message'] to the 'names' argument of read_table().\n",
    "* Print the first five values of the dataframe with the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Pandas display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Display all columns of a dataframe\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "import pandas as pd\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "# Output printing out first 5 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Data Preprocessing ###\n",
    "\n",
    "Now that we have a basic understanding of what our dataset looks like, lets convert our labels to binary variables, 0 to represent 'ham'(i.e. not spam) and 1 to represent 'spam' for ease of computation. \n",
    "\n",
    "You might be wondering why do we need to do this step? The answer to this lies in how scikit-learn handles inputs. Scikit-learn only deals with numerical values and hence if we were to leave our label values as strings, scikit-learn would do the conversion internally(more specifically, the string labels will be cast to unknown float values). \n",
    "\n",
    "Our model would still be able to make predictions if we left our labels as strings but we could have issues later when calculating performance metrics, for example when calculating our precision and recall scores. Hence, to avoid unexpected 'gotchas' later, it is good practice to have our categorical values be fed into our model as integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Instructions: **\n",
    "* Convert the values in the 'label' colum to numerical values using map method as follows:\n",
    "{'ham':0, 'spam':1} This maps the 'ham' value to 0 and the 'spam' value to 1.\n",
    "* Also, to get an idea of the size of the dataset we are dealing with, print out number of rows and columns using \n",
    "'shape'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "print(df.shape)\n",
    "df.head() # returns (rows, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Bag of words ###\n",
    "\n",
    "What we have here in our data set is a large collection of text data (5,572 rows of data). Most ML algorithms rely on numerical data to be fed into them as input, and email/sms messages are usually text heavy. \n",
    "\n",
    "Here we'd like to introduce the Bag of Words(BoW) concept which is a term used to specify the problems that have a 'bag of words' or a collection of text data that needs to be worked with. The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter. \n",
    "\n",
    "Using a process which we will go through now, we can covert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrance of each word or token in that document.\n",
    "\n",
    "For example: \n",
    "\n",
    "Lets say we have 4 documents as follows:\n",
    "\n",
    "`['Hello, how are you!',\n",
    "'Win money, win from home.',\n",
    "'Call me now',\n",
    "'Hello, Call you tomorrow?']`\n",
    "\n",
    "Our objective here is to convert this set of text to a frequency distribution matrix, as follows:\n",
    "\n",
    "<img src=\"images/countvectorizer.png\" height=\"542\" width=\"542\">\n",
    "\n",
    "Here as we can see, the documents are numbered in the rows, and each word is a column name, with the corresponding value being the frequency of that word in the document.\n",
    "\n",
    "Lets break this down and see how we can do this conversion using a small set of documents.\n",
    "\n",
    "To handle this, we will be using sklearns \n",
    "[count vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) method which does the following:\n",
    "\n",
    "* It tokenizes the string(separates the string into individual words) and gives an integer ID to each token.\n",
    "* It counts the occurrance of each of those tokens.\n",
    "\n",
    "** Please Note: ** \n",
    "\n",
    "* The CountVectorizer method automatically converts all tokenized words to their lower case form so that it does not treat words like 'He' and 'he' differently. It does this using the `lowercase` parameter which is by default set to `True`.\n",
    "\n",
    "* It also ignores all punctuation so that words followed by a punctuation mark (for example: 'hello!') are not treated differently than the same words not prefixed or suffixed by a punctuation mark (for example: 'hello'). It does this using the `token_pattern` parameter which has a default regular expression which selects tokens of 2 or more alphanumeric characters.\n",
    "\n",
    "* The third parameter to take note of is the `stop_words` parameter. Stop words refer to the most commonly used words in a language. They include words like 'am', 'an', 'and', 'the' etc. By setting this parameter value to `english`, CountVectorizer will automatically ignore all words(from our input text) that are found in the built in list of english stop words in scikit-learn. This is extremely helpful as stop words can skew our calculations when we are trying to find certain key words that are indicative of spam.\n",
    "\n",
    "We will dive into the application of each of these into our model in a later step, but for now it is important to be aware of such preprocessing techniques available to us when dealing with textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Implementing Bag of Words from scratch ###\n",
    "\n",
    "Before we dive into scikit-learn's Bag of Words(BoW) library to do the dirty work for us, let's implement it ourselves first so that we can understand what's happening behind the scenes. \n",
    "\n",
    "** Step 1: Convert all strings to their lower case form. **\n",
    "\n",
    "Let's say we have a document set:\n",
    "\n",
    "```\n",
    "documents = ['Hello, how are you!',\n",
    "             'Win money, win from home.',\n",
    "             'Call me now.',\n",
    "             'Hello, Call hello you tomorrow?']\n",
    "```\n",
    ">>** Instructions: **\n",
    "* Convert all the strings in the documents set to their lower case. Save them into a list called 'lower_case_documents'. You can convert strings to their lower case in python by using the lower() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello, how are you!', 'win money, win from home.', 'call me now.', 'hello, call hello you tomorrow?']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution:\n",
    "'''\n",
    "documents = ['Hello, how are you!',\n",
    "             'Win money, win from home.',\n",
    "             'Call me now.',\n",
    "             'Hello, Call hello you tomorrow?']\n",
    "\n",
    "lower_case_documents = []\n",
    "for i in documents:\n",
    "    lower_case_documents.append(i.lower())\n",
    "print(lower_case_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2: Removing all punctuations **\n",
    "\n",
    ">>**Instructions: **\n",
    "Remove all punctuation from the strings in the document set. Save them into a list called \n",
    "'sans_punctuation_documents'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 36: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 43: None,\n",
       " 44: None,\n",
       " 45: None,\n",
       " 46: None,\n",
       " 47: None,\n",
       " 58: None,\n",
       " 59: None,\n",
       " 60: None,\n",
       " 61: None,\n",
       " 62: None,\n",
       " 63: None,\n",
       " 64: None,\n",
       " 91: None,\n",
       " 92: None,\n",
       " 93: None,\n",
       " 94: None,\n",
       " 95: None,\n",
       " 96: None,\n",
       " 123: None,\n",
       " 124: None,\n",
       " 125: None,\n",
       " 126: None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello how are you', 'win money win from home', 'call me now', 'hello call hello you tomorrow']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution:\n",
    "'''\n",
    "sans_punctuation_documents = []\n",
    "import string\n",
    "\n",
    "for i in lower_case_documents:\n",
    "    sans_punctuation_documents.append(i.translate(str.maketrans('', '', string.punctuation)))\n",
    "print(sans_punctuation_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 3: Tokenization **\n",
    "\n",
    "Tokenizing a sentence in a document set means splitting up a sentence into individual words using a delimiter. The delimiter specifies what character we will use to identify the beginning and the end of a word(for example we could use a single space as the delimiter for identifying words in our document set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**Instructions:**\n",
    "Tokenize the strings stored in 'sans_punctuation_documents' using the split() method. and store the final document set \n",
    "in a list called 'preprocessed_documents'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'how', 'are', 'you'], ['win', 'money', 'win', 'from', 'home'], ['call', 'me', 'now'], ['hello', 'call', 'hello', 'you', 'tomorrow']]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution:\n",
    "'''\n",
    "preprocessed_documents = []\n",
    "for i in sans_punctuation_documents:\n",
    "    preprocessed_documents.append(i.split(' '))\n",
    "print(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 4: Count frequencies **\n",
    "\n",
    "Now that we have our document set in the required format, we can proceed to counting the occurrence of each word in each document of the document set. We will use the `Counter` method from the Python `collections` library for this purpose. \n",
    "\n",
    "`Counter` counts the occurrence of each item in the list and returns a dictionary with the key as the item being counted and the corresponding value being the count of that item in the list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**Instructions:**\n",
    "Using the Counter() method and preprocessed_documents as the input, create a dictionary with the keys being each word in each document and the corresponding values being the frequncy of occurrence of that word. Save each Counter dictionary as an item in a list called 'frequency_list'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'hello': 1, 'how': 1, 'are': 1, 'you': 1}),\n",
      " Counter({'win': 2, 'money': 1, 'from': 1, 'home': 1}),\n",
      " Counter({'call': 1, 'me': 1, 'now': 1}),\n",
      " Counter({'hello': 2, 'call': 1, 'you': 1, 'tomorrow': 1})]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "frequency_list = []\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "for i in preprocessed_documents:\n",
    "    frequency_counts = Counter(i)\n",
    "    frequency_list.append(frequency_counts)\n",
    "pprint.pprint(frequency_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have implemented the Bag of Words process from scratch! As we can see in our previous output, we have a frequency distribution dictionary which gives a clear view of the text that we are dealing with.\n",
    "\n",
    "We should now have a solid understanding of what is happening behind the scenes in the `sklearn.feature_extraction.text.CountVectorizer` method of scikit-learn. \n",
    "\n",
    "We will now implement `sklearn.feature_extraction.text.CountVectorizer` method in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Implementing Bag of Words in scikit-learn ###\n",
    "\n",
    "Now that we have implemented the BoW concept from scratch, let's go ahead and use scikit-learn to do this process in a clean and succinct way. We will use the same document set as we used in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will look to create a frequency matrix on a smaller document set to make sure we understand how the \n",
    "document-term matrix generation happens. We have created a sample document set 'documents'.\n",
    "'''\n",
    "documents = ['Hello, how are you!',\n",
    "                'Win money, win from home.',\n",
    "                'Call me now.',\n",
    "                'Hello, Call hello you tomorrow?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**Instructions:**\n",
    "Import the sklearn.feature_extraction.text.CountVectorizer method and create an instance of it called 'count_vector'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data preprocessing with CountVectorizer() **\n",
    "\n",
    "In Step 2.2, we implemented a version of the CountVectorizer() method from scratch that entailed cleaning our data first. This cleaning involved converting all of our data to lower case and removing all punctuation marks. CountVectorizer() has certain parameters which take care of these steps for us. They are:\n",
    "\n",
    "* `lowercase = True`\n",
    "    \n",
    "    The `lowercase` parameter has a default value of `True` which converts all of our text to its lower case form.\n",
    "\n",
    "\n",
    "* `token_pattern = (?u)\\\\b\\\\w\\\\w+\\\\b`\n",
    "    \n",
    "    The `token_pattern` parameter has a default regular expression value of `(?u)\\\\b\\\\w\\\\w+\\\\b` which ignores all punctuation marks and treats them as delimiters, while accepting alphanumeric strings of length greater than or equal to 2, as individual tokens or words.\n",
    "\n",
    "\n",
    "* `stop_words`\n",
    "\n",
    "    The `stop_words` parameter, if set to `english` will remove all words from our document set that match a list of English stop words which is defined in scikit-learn. Considering the size of our dataset and the fact that we are dealing with SMS messages and not larger text sources like e-mail, we will not be setting this parameter value.\n",
    "\n",
    "You can take a look at all the parameter values of your `count_vector` object by simply printing out the object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Practice node:\n",
    "Print the 'count_vector' object which is an instance of 'CountVectorizer()'\n",
    "'''\n",
    "print(count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**Instructions:**\n",
    "Fit your document dataset to the CountVectorizer object you have created using fit(), and get the list of words \n",
    "which have been categorized as features using the get_feature_names() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, how are you!',\n",
       " 'Win money, win from home.',\n",
       " 'Call me now.',\n",
       " 'Hello, Call hello you tomorrow?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'call',\n",
       " 'from',\n",
       " 'hello',\n",
       " 'home',\n",
       " 'how',\n",
       " 'me',\n",
       " 'money',\n",
       " 'now',\n",
       " 'tomorrow',\n",
       " 'win',\n",
       " 'you']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution:\n",
    "'''\n",
    "count_vector.fit(documents)\n",
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_feature_names()` method returns our feature names for this dataset, which is the set of words that make up our vocabulary for 'documents'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**\n",
    "Instructions:**\n",
    "Create a matrix with the rows being each of the 4 documents, and the columns being each word. \n",
    "The corresponding (row, column) value is the frequency of occurrance of that word(in the column) in a particular\n",
    "document(in the row). You can do this using the transform() method and passing in the document data set as the \n",
    "argument. The transform() method returns a matrix of numpy integers, you can convert this to an array using\n",
    "toarray(). Call the array 'doc_array'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "doc_array = count_vector.transform(documents).toarray()\n",
    "doc_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a clean representation of the documents in terms of the frequency distribution of the words in them. To make it easier to understand our next step is to convert this array into a dataframe and name the columns appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**Instructions:**\n",
    "Convert the array we obtained, loaded into 'doc_array', into a dataframe and set the column names to \n",
    "the word names(which you computed earlier using get_feature_names(). Call the dataframe 'frequency_matrix'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>call</th>\n",
       "      <th>from</th>\n",
       "      <th>hello</th>\n",
       "      <th>home</th>\n",
       "      <th>how</th>\n",
       "      <th>me</th>\n",
       "      <th>money</th>\n",
       "      <th>now</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>win</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
       "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
       "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
       "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
       "3    0     1     0      2     0    0   0      0    0         1    0    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "frequency_matrix = pd.DataFrame(doc_array, \n",
    "                                columns = count_vector.get_feature_names())\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully implemented a Bag of Words problem for a document dataset that we created. \n",
    "\n",
    "One potential issue that can arise from using this method out of the box is the fact that if our dataset of text is extremely large(say if we have a large collection of news articles or email data), there will be certain values that are more common that others simply due to the structure of the language itself. So for example words like 'is', 'the', 'an', pronouns, grammatical contructs etc could skew our matrix and affect our analyis. \n",
    "\n",
    "There are a couple of ways to mitigate this. One way is to use the `stop_words` parameter and set its value to `english`. This will automatically ignore all words(from our input text) that are found in a built in list of English stop words in scikit-learn.\n",
    "\n",
    "Another way of mitigating this is by using the [tfidf](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) method. This method is out of scope for the context of this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Training and testing sets ###\n",
    "\n",
    "Now that we have understood how to deal with the Bag of Words problem we can get back to our dataset and proceed with our analysis. Our first step in this regard would be to split our dataset into a training and testing set so we can test our model later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">>**Instructions:**\n",
    "Split the dataset into a training and testing set by using the train_test_split method in sklearn. Split the data\n",
    "using the following variables:\n",
    "* `X_train` is our training data for the 'sms_message' column.\n",
    "* `y_train` is our training data for the 'label' column\n",
    "* `X_test` is our testing data for the 'sms_message' column.\n",
    "* `y_test` is our testing data for the 'label' column\n",
    "Print out the number of rows we have in each our training and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 5572\n",
      "Number of rows in the training set: 4179\n",
      "Number of rows in the test set: 1393\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "\n",
    "NOTE: sklearn.cross_validation will be deprecated soon to sklearn.model_selection \n",
    "'''\n",
    "# split into training and testing sets\n",
    "# USE from sklearn.model_selection import train_test_split to avoid seeing deprecation warning.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710     4mths half price Orange line rental & latest c...\n",
       "3740                           Did you stitch his trouser\n",
       "2711    Hope you enjoyed your new content. text stop t...\n",
       "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
       "3748    Ãœ neva tell me how i noe... I'm not at home in...\n",
       "2389    wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...\n",
       "3464    i am seeking a lady in the street and a freak ...\n",
       "772     Lol! U drunkard! Just doing my hair at d momen...\n",
       "3667    I'm turning off my phone. My moms telling ever...\n",
       "4955    U coming back 4 dinner rite? Dad ask me so i r...\n",
       "854     AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...\n",
       "4079                  Gam gone after outstanding innings.\n",
       "2837                         Nice.nice.how is it working?\n",
       "1392                  Haha just kidding, papa needs drugs\n",
       "5533    Hey chief, can you give me a bell when you get...\n",
       "874     Ugh its been a long day. I'm exhausted. Just w...\n",
       "4408    Awesome, plan to get here any time after like ...\n",
       "3990    Ok lor. Anyway i thk we cant get tickets now c...\n",
       "1921                        Dont know you bring some food\n",
       "749     Is there a reason we've not spoken this year? ...\n",
       "2947                        make that 3! 4 fucks sake?! x\n",
       "2378    YES! The only place in town to meet exciting a...\n",
       "83                   You will be in the place of that man\n",
       "4668                           I send the print  outs da.\n",
       "128                                Are you there in room.\n",
       "4521    What to think no one saying clearly. Ok leave ...\n",
       "5090                             St andre, virgil's cream\n",
       "885     Yoyyooo u know how to change permissions for a...\n",
       "134     Sunshine Quiz Wkly Q! Win a top Sony DVD playe...\n",
       "3060    Dear all, as we know  &lt;#&gt; th is the  &lt...\n",
       "                              ...                        \n",
       "1031    Can not use foreign stamps in this country. Go...\n",
       "1110                      S s..first time..dhoni rocks...\n",
       "1888    Urgent! Please call 09061743811 from landline....\n",
       "3550    I got like $ &lt;#&gt; , I can get some more l...\n",
       "1527    Wow ... I love you sooo much, you know ? I can...\n",
       "753                           Dont gimme that lip caveboy\n",
       "3049             Die... Now i have e toot fringe again...\n",
       "2628    I know I'm lacking on most of this particular ...\n",
       "562                      Thanx 4 e brownie it's v nice...\n",
       "4764                           Prepare to be pleasured :)\n",
       "3562    Text BANNEDUK to 89555 to see! cost 150p texto...\n",
       "252     Wen ur lovable bcums angry wid u, dnt take it ...\n",
       "2516    Bognor it is! Should be splendid at this time ...\n",
       "2962    I'm doing da intro covers energy trends n pros...\n",
       "4453    I've told you everything will stop. Just dont ...\n",
       "5374    Do u konw waht is rael FRIENDSHIP Im gving yuo...\n",
       "5396             As in i want custom officer discount oh.\n",
       "1202                                 I know she called me\n",
       "3462    K.. I yan jiu liao... Sat we can go 4 bugis vi...\n",
       "2797    Tell your friends what you plan to do on Valen...\n",
       "4225    Double eviction this week - Spiral and Michael...\n",
       "144            I know you are. Can you pls open the back?\n",
       "5056    Am on a train back from northampton so i'm afr...\n",
       "2895                     K...k...yesterday i was in cbe .\n",
       "2763    ARR birthday today:) i wish him to get more os...\n",
       "905     We're all getting worried over here, derek and...\n",
       "5192    Oh oh... Den muz change plan liao... Go back h...\n",
       "3980    CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
       "235     Text & meet someone sexy today. U can find a d...\n",
       "5157                              K k:) sms chat with me.\n",
       "Name: sms_message, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710     spam\n",
       "3740     ham\n",
       "2711    spam\n",
       "3155    spam\n",
       "3748     ham\n",
       "2389     ham\n",
       "3464     ham\n",
       "772      ham\n",
       "3667     ham\n",
       "4955     ham\n",
       "854      ham\n",
       "4079     ham\n",
       "2837     ham\n",
       "1392     ham\n",
       "5533     ham\n",
       "874      ham\n",
       "4408     ham\n",
       "3990     ham\n",
       "1921     ham\n",
       "749      ham\n",
       "2947     ham\n",
       "2378    spam\n",
       "83       ham\n",
       "4668     ham\n",
       "128      ham\n",
       "4521     ham\n",
       "5090     ham\n",
       "885      ham\n",
       "134     spam\n",
       "3060     ham\n",
       "        ... \n",
       "1031     ham\n",
       "1110     ham\n",
       "1888    spam\n",
       "3550     ham\n",
       "1527     ham\n",
       "753      ham\n",
       "3049     ham\n",
       "2628     ham\n",
       "562      ham\n",
       "4764     ham\n",
       "3562    spam\n",
       "252      ham\n",
       "2516     ham\n",
       "2962     ham\n",
       "4453     ham\n",
       "5374     ham\n",
       "5396     ham\n",
       "1202     ham\n",
       "3462     ham\n",
       "2797     ham\n",
       "4225     ham\n",
       "144      ham\n",
       "5056     ham\n",
       "2895     ham\n",
       "2763     ham\n",
       "905      ham\n",
       "5192     ham\n",
       "3980     ham\n",
       "235     spam\n",
       "5157     ham\n",
       "Name: label, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Applying Bag of Words processing to our dataset. ###\n",
    "\n",
    "Now that we have split the data, our next objective is to follow the steps from Step 2: Bag of words and convert our data into the desired matrix format. To do this we will be using CountVectorizer() as we did before. There are two  steps to consider here:\n",
    "\n",
    "* Firstly, we have to fit our training data (`X_train`) into `CountVectorizer()` and return the matrix.\n",
    "* Secondly, we have to transform our testing data (`X_test`) to return the matrix. \n",
    "\n",
    "Note that `X_train` is our training data for the 'sms_message' column in our dataset and we will be using this to train our model. \n",
    "\n",
    "`X_test` is our testing data for the 'sms_message' column and this is the data we will be using(after transformation to a matrix) to make predictions on. We will then compare those predictions with `y_test` in a later step. \n",
    "\n",
    "For now, we have provided the code that does the matrix transformations for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "[Practice Node]\n",
    "\n",
    "The code for this segment is in 2 parts. Firstly, we are learning a vocabulary dictionary for the training data \n",
    "and then transforming the data into a document-term matrix; secondly, for the testing data we are only \n",
    "transforming the data into a document-term matrix.\n",
    "\n",
    "This is similar to the process we followed in Step 2.3\n",
    "\n",
    "We will provide the transformed data to students in the variables 'training_data' and 'testing_data'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Bayes Theorem implementation from scratch ###\n",
    "\n",
    "Now that we have our dataset in the format that we need, we can move onto the next portion of our mission which is the  algorithm we will use to make our predictions to classify a message as spam or not spam. Remember that at the start of the mission we briefly discussed the Bayes theorem but now we shall go into a little more detail. In layman's terms, the Bayes theorem calculates the probability of an event occurring, based on certain other probabilities that are related to the event in question. It is  composed of a  prior(the probabilities that we are aware of or that is given to us) and the posterior(the probabilities we are looking to compute using the priors). \n",
    "\n",
    "Let us implement the Bayes Theorem from scratch using a simple example. Let's say we are trying to find the odds of an individual having diabetes, given that he or she was tested for it and got a positive result. \n",
    "In the medical field, such probabilies play a very important role as it usually deals with life and death situatuations. \n",
    "\n",
    "We assume the following:\n",
    "\n",
    "`P(D)` is the probability of a person having Diabetes. It's value is `0.01` or in other words, 1% of the general population has diabetes(Disclaimer: these values are assumptions and are not reflective of any medical study).\n",
    "\n",
    "`P(Pos)` is the probability of getting a positive test result.\n",
    "\n",
    "`P(Neg)` is the probability of getting a negative test result.\n",
    "\n",
    "`P(Pos|D)` is the probability of getting a positive result on a test done for detecting diabetes, given that you have diabetes. This has a value `0.9`. In other words the test is correct 90% of the time. This is also called the Sensitivity or True Positive Rate.\n",
    "\n",
    "`P(Neg|~D)` is the probability of getting a negative result on a test done for detecting diabetes, given that you do not have diabetes. This also has a value of `0.9` and is therefore correct, 90% of the time. This is also called the Specificity or True Negative Rate.\n",
    "\n",
    "The Bayes formula is as follows:\n",
    "\n",
    "<img src=\"images/bayes_formula.png\" height=\"242\" width=\"242\">\n",
    "\n",
    "* `P(A)` is the prior probability of A occuring independantly. In our example this is `P(D)`. This value is given to us.\n",
    "\n",
    "* `P(B)` is the prior probability of B occuring independantly. In our example this is `P(Pos)`.\n",
    "\n",
    "* `P(A|B)` is the posterior probability that A occurs given B. In our example this is `P(D|Pos)`. That is, **the probability of an individual having diabetes, given that, that individual got a positive test result. This is the value that we are looking to calculate.**\n",
    "\n",
    "* `P(B|A)` is the likelihood probability of B occuring, given A. In our example this is `P(Pos|D)`. This value is given to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting our values into the formula for Bayes theorem we get:\n",
    "\n",
    "`P(D|Pos) = (P(D) * P(Pos|D) / P(Pos)`\n",
    "\n",
    "The probability of getting a positive test result `P(Pos)` can be calulated using the Sensitivity and Specificity as follows:\n",
    "\n",
    "`P(Pos) = [P(D) * Sensitivity] + [P(~D) * (1-Specificity))]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Calculate probability of getting a positive test result, P(Pos)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of getting a positive test result P(Pos) is: {} 0.10799999999999998\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution (skeleton code will be provided)\n",
    "'''\n",
    "# P(D)\n",
    "p_diabetes = 0.01\n",
    "\n",
    "# P(~D)\n",
    "p_no_diabetes = 0.99\n",
    "\n",
    "# Sensitivity or P(Pos|D)\n",
    "p_pos_diabetes = 0.9\n",
    "\n",
    "# Specificity or P(Neg/~D)\n",
    "p_neg_no_diabetes = 0.9\n",
    "\n",
    "# P(Pos)\n",
    "p_pos = (p_diabetes * p_pos_diabetes) + (p_no_diabetes * (1 - p_neg_no_diabetes))\n",
    "print('The probability of getting a positive test result P(Pos) is: {}',format(p_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Using all of this information we can calculate our posteriors as follows: **\n",
    "    \n",
    "The probability of an individual having diabetes, given that, that individual got a positive test result:\n",
    "\n",
    "`P(D/Pos) = (P(D) * Sensitivity)) / P(Pos)`\n",
    "\n",
    "The probability of an individual not having diabetes, given that, that individual got a positive test result:\n",
    "\n",
    "`P(~D/Pos) = (P(~D) * (1-Specificity)) / P(Pos)`\n",
    "\n",
    "The sum of our posteriors will always equal `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Compute the probability of an individual having diabetes, given that, that individual got a positive test result.\n",
    "In other words, compute P(D|Pos).\n",
    "\n",
    "The formula is: P(D|Pos) = (P(D) * P(Pos|D) / P(Pos)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of an individual having diabetes, given that that individual got a positive test result is: 0.08333333333333336\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "# P(D|Pos)\n",
    "p_diabetes_pos = (p_diabetes * p_pos_diabetes) / p_pos\n",
    "print('Probability of an individual having diabetes, given that that individual got a positive test result is:\\\n",
    "',format(p_diabetes_pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Compute the probability of an individual not having diabetes, given that, that individual got a positive test result.\n",
    "In other words, compute P(~D|Pos).\n",
    "\n",
    "The formula is: P(~D|Pos) = (P(~D) * P(Pos|~D) / P(Pos)\n",
    "\n",
    "Note that P(Pos/~D) can be computed as 1 - P(Neg/~D). \n",
    "\n",
    "Therefore:\n",
    "P(Pos/~D) = p_pos_no_diabetes = 1 - 0.9 = 0.1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of an individual not having diabetes, given that that individual got a positive test result is: 0.9166666666666669\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "# P(Pos/~D)\n",
    "p_pos_no_diabetes = 0.1\n",
    "\n",
    "# P(~D|Pos)\n",
    "p_no_diabetes_pos = (p_no_diabetes * p_pos_no_diabetes) / p_pos\n",
    "print ('Probability of an individual not having diabetes, given that that individual got a positive test result is:'\n",
    ",p_no_diabetes_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have implemented Bayes theorem from scratch. Your analysis shows that even if you get a positive test result, there is only a 8.3% chance that you actually have diabetes and a 91.67% chance that you do not have diabetes. This is of course assuming that only 1% of the entire population has diabetes which of course is only an assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What does the term 'Naive' in 'Naive Bayes' mean ? ** \n",
    "\n",
    "The term 'Naive' in Naive Bayes comes from the fact that the algorithm considers the features that it is using to make the predictions to be independent of each other, which may not always be the case. So in our Diabetes example, we are considering only one feature, that is the test result. Say we added another feature, 'exercise'. Let's say this feature has a binary value of `0` and `1`, where the former signifies that the individual exercises less than or equal to 2 days a week and the latter signifies that the individual exercises greater than or equal to 3 days a week. If we had to use both of these features, namely the test result and the value of the 'exercise' feature, to compute our final probabilities, Bayes' theorem would fail. Naive Bayes' is an extension of Bayes' theorem that assumes that all the features are independent of each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Naive Bayes implementation from scratch ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have understood the ins and outs of Bayes Theorem, we will extend it to consider cases where we have more than feature. \n",
    "\n",
    "Let's say that we have two political parties' candidates, 'Jill Stein' of the Green Party and 'Gary Johnson' of the Libertarian Party and we have the probabilities of each of these candidates saying the words 'freedom', 'immigration' and 'environment' when they give a speech:\n",
    "\n",
    "* Probability that Jill Stein says 'freedom': 0.1 ---------> `P(F|J)`\n",
    "* Probability that Jill Stein says 'immigration': 0.1 -----> `P(I|J)`\n",
    "* Probability that Jill Stein says 'environment': 0.8 -----> `P(E|J)`\n",
    "\n",
    "\n",
    "* Probability that Gary Johnson says 'freedom': 0.7 -------> `P(F|G)`\n",
    "* Probability that Gary Johnson says 'immigration': 0.2 ---> `P(I|G)`\n",
    "* Probability that Gary Johnson says 'environment': 0.1 ---> `P(E|G)`\n",
    "\n",
    "\n",
    "And let us also assume that the probablility of Jill Stein giving a speech, `P(J)` is `0.5` and the same for Gary Johnson, `P(G) = 0.5`. \n",
    "\n",
    "\n",
    "Given this, what if we had to find the probabilities of Jill Stein saying the words 'freedom' and 'immigration'? This is where the Naive Bayes'theorem comes into play as we are considering two features, 'freedom' and 'immigration'.\n",
    "\n",
    "Now we are at a place where we can define the formula for the Naive Bayes' theorem:\n",
    "\n",
    "<img src=\"images/naivebayes.png\" height=\"342\" width=\"342\">\n",
    "\n",
    "Here, `y` is the class variable or in our case the name of the candidate and `x1` through `xn` are the feature vectors or in our case the individual words. The theorem makes the assumption that each of the feature vectors or words (`xi`) are independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To break this down, we have to compute the following posterior probabilities:\n",
    "\n",
    "* `P(J|F,I)`: Probability of Jill Stein saying the words Freedom and Immigration. \n",
    "\n",
    "    Using the formula and our knowledge of Bayes' theorem, we can compute this as follows: `P(J|F,I)` = `(P(J) * P(F|J) * P(I|J)) / P(F,I)`. Here `P(F,I)` is the probability of the words 'freedom' and 'immigration' being said in a speech.\n",
    "    \n",
    "\n",
    "* `P(G|F,I)`: Probability of Gary Johnson saying the words Freedom and Immigration.  \n",
    "    \n",
    "    Using the formula, we can compute this as follows: `P(G|F,I)` = `(P(G) * P(F|G) * P(I|G)) / P(F,I)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions: Compute the probability of the words 'freedom' and 'immigration' being said in a speech, or\n",
    "P(F,I).\n",
    "\n",
    "The first step is multiplying the probabilities of Jill Stein giving a speech with her individual \n",
    "probabilities of saying the words 'freedom' and 'immigration'. Store this in a variable called p_j_text\n",
    "\n",
    "The second step is multiplying the probabilities of Gary Johnson giving a speech with his individual \n",
    "probabilities of saying the words 'freedom' and 'immigration'. Store this in a variable called p_g_text\n",
    "\n",
    "The third step is to add both of these probabilities and you will get P(F,I).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005000000000000001\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution: Step 1\n",
    "'''\n",
    "# P(J)\n",
    "p_j = 0.5\n",
    "\n",
    "# P(F/J)\n",
    "p_j_f = 0.1\n",
    "\n",
    "# P(I/J)\n",
    "p_j_i = 0.1\n",
    "\n",
    "p_j_text = p_j * p_j_f * p_j_i\n",
    "print(p_j_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06999999999999999\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution: Step 2\n",
    "'''\n",
    "# P(G)\n",
    "p_g = 0.5\n",
    "\n",
    "# P(F/G)\n",
    "p_g_f = 0.7\n",
    "\n",
    "# P(I/G)\n",
    "p_g_i = 0.2\n",
    "\n",
    "p_g_text = p_g * p_g_f * p_g_i\n",
    "print(p_g_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of words freedom and immigration being said are:  0.075\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution: Step 3: Compute P(F,I) and store in p_f_i\n",
    "'''\n",
    "p_f_i = p_j_text + p_g_text\n",
    "print('Probability of words freedom and immigration being said are: ', format(p_f_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the probability of `P(J|F,I)`, that is the probability of Jill Stein saying the words Freedom and Immigration and `P(G|F,I)`, that is the probability of Gary Johnson saying the words Freedom and Immigration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Compute P(J|F,I) using the formula P(J|F,I) = (P(J) * P(F|J) * P(I|J)) / P(F,I) and store it in a variable p_j_fi\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of Jill Stein saying the words Freedom and Immigration:  0.06666666666666668\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "p_j_fi = p_j_text / p_f_i\n",
    "print('The probability of Jill Stein saying the words Freedom and Immigration: ', format(p_j_fi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInstructions:\\nCompute P(G|F,I) using the formula P(G|F,I) = (P(G) * P(F|G) * P(I|G)) / P(F,I) and store it in a variable p_g_fi\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Compute P(G|F,I) using the formula P(G|F,I) = (P(G) * P(F|G) * P(I|G)) / P(F,I) and store it in a variable p_g_fi\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of Gary Johnson saying the words Freedom and Immigration:  0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "p_g_fi = p_g_text / p_f_i\n",
    "print('The probability of Gary Johnson saying the words Freedom and Immigration: ', format(p_g_fi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we can see, just like in the Bayes' theorem case, the sum of our posteriors is equal to 1. Congratulations! You have implemented the Naive Bayes' theorem from scratch. Our analysis shows that there is only a 6.6% chance that Jill Stein of the Green Party uses the words 'freedom' and 'immigration' in her speech as compard the the 93.3% chance for Gary Johnson of the Libertarian party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another more generic example of Naive Bayes' in action is as when we search for the term 'Sacramento Kings' in a search engine. In order for us to get the results pertaining to the Scramento Kings NBA basketball team, the search engine needs to be able to associate the two words together and not treat them individually, in which case we would get results of images tagged with 'Sacramento' like pictures of city landscapes and images of 'Kings' which could be pictures of crowns or kings from history when what we are looking to get are images of the basketball team. This is a classic case of the search engine treating the words as independant entities and hence being 'naive' in its approach. \n",
    "\n",
    "\n",
    "Applying this to our problem of classifying messages as spam, the Naive Bayes algorithm *looks at each word individually and not as associated entities* with any kind of link between them. In the case of spam detectors, this usually works as there are certain red flag words which can almost guarantee its classification as spam, for example emails with words like 'viagra' are usually classified as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Naive Bayes implementation using scikit-learn ###\n",
    "\n",
    "Thankfully, sklearn has several Naive Bayes implementations that we can use and so we do not have to do the math from scratch. We will be using sklearns `sklearn.naive_bayes` method to make predictions on our dataset. \n",
    "\n",
    "Specifically, we will be using the multinomial Naive Bayes implementation. This particular classifier is suitable for classification with discrete features (such as in our case, word counts for text classification). It takes in integer word counts as its input. On the other hand Gaussian Naive Bayes is better suited for continuous data as it assumes that the input data has a Gaussian(normal) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nInstructions:\\n\\nWe have loaded the training data into the variable 'training_data' and the testing data into the \\nvariable 'testing_data'.\\n\\nImport the MultinomialNB classifier and fit the training data into the classifier using fit(). Name your classifier\\n'naive_bayes'. You will be training the classifier using 'training_data' and y_train' from our split earlier. \\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Instructions:\n",
    "\n",
    "We have loaded the training data into the variable 'training_data' and the testing data into the \n",
    "variable 'testing_data'.\n",
    "\n",
    "Import the MultinomialNB classifier and fit the training data into the classifier using fit(). Name your classifier\n",
    "'naive_bayes'. You will be training the classifier using 'training_data' and y_train' from our split earlier. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710     spam\n",
       "3740     ham\n",
       "2711    spam\n",
       "3155    spam\n",
       "3748     ham\n",
       "2389     ham\n",
       "3464     ham\n",
       "772      ham\n",
       "3667     ham\n",
       "4955     ham\n",
       "854      ham\n",
       "4079     ham\n",
       "2837     ham\n",
       "1392     ham\n",
       "5533     ham\n",
       "874      ham\n",
       "4408     ham\n",
       "3990     ham\n",
       "1921     ham\n",
       "749      ham\n",
       "2947     ham\n",
       "2378    spam\n",
       "83       ham\n",
       "4668     ham\n",
       "128      ham\n",
       "4521     ham\n",
       "5090     ham\n",
       "885      ham\n",
       "134     spam\n",
       "3060     ham\n",
       "2846     ham\n",
       "1681     ham\n",
       "4988     ham\n",
       "1937     ham\n",
       "3192    spam\n",
       "522      ham\n",
       "3732     ham\n",
       "2442     ham\n",
       "4536     ham\n",
       "3463    spam\n",
       "2535     ham\n",
       "111      ham\n",
       "3604     ham\n",
       "2588     ham\n",
       "5539     ham\n",
       "1441     ham\n",
       "3720    spam\n",
       "3773     ham\n",
       "2126     ham\n",
       "2739     ham\n",
       "2164     ham\n",
       "2707     ham\n",
       "1273     ham\n",
       "2010     ham\n",
       "5484     ham\n",
       "2932     ham\n",
       "1098     ham\n",
       "3571    spam\n",
       "2501     ham\n",
       "3197     ham\n",
       "3468    spam\n",
       "1147     ham\n",
       "1432     ham\n",
       "748     spam\n",
       "1990     ham\n",
       "2868     ham\n",
       "910     spam\n",
       "2159     ham\n",
       "304      ham\n",
       "2300    spam\n",
       "4204     ham\n",
       "3716     ham\n",
       "5247     ham\n",
       "5438     ham\n",
       "4428     ham\n",
       "3560    spam\n",
       "2361     ham\n",
       "3770     ham\n",
       "3158     ham\n",
       "2961     ham\n",
       "107      ham\n",
       "1794     ham\n",
       "120     spam\n",
       "2993     ham\n",
       "2827     ham\n",
       "4405     ham\n",
       "364      ham\n",
       "4296    spam\n",
       "1156     ham\n",
       "1277     ham\n",
       "3451     ham\n",
       "872      ham\n",
       "898      ham\n",
       "4856     ham\n",
       "3784     ham\n",
       "3774     ham\n",
       "5183     ham\n",
       "3806     ham\n",
       "4104    spam\n",
       "1549     ham\n",
       "2132     ham\n",
       "1165     ham\n",
       "3869     ham\n",
       "1877     ham\n",
       "791      ham\n",
       "5413     ham\n",
       "1524     ham\n",
       "700      ham\n",
       "4882     ham\n",
       "3472     ham\n",
       "1751     ham\n",
       "3590     ham\n",
       "3419    spam\n",
       "4126     ham\n",
       "3715     ham\n",
       "1759     ham\n",
       "5139     ham\n",
       "1743     ham\n",
       "770      ham\n",
       "4254     ham\n",
       "2907     ham\n",
       "4322     ham\n",
       "55       ham\n",
       "115      ham\n",
       "4881     ham\n",
       "2263     ham\n",
       "2234     ham\n",
       "3840     ham\n",
       "2193     ham\n",
       "1727     ham\n",
       "2543     ham\n",
       "3992     ham\n",
       "2475     ham\n",
       "3006     ham\n",
       "3458     ham\n",
       "2379     ham\n",
       "4396     ham\n",
       "5370    spam\n",
       "3638     ham\n",
       "4817     ham\n",
       "2236     ham\n",
       "921      ham\n",
       "1427     ham\n",
       "1723     ham\n",
       "1831     ham\n",
       "2089    spam\n",
       "3300     ham\n",
       "4262     ham\n",
       "187      ham\n",
       "3267     ham\n",
       "3496    spam\n",
       "4294     ham\n",
       "1915    spam\n",
       "2174     ham\n",
       "4883     ham\n",
       "4761     ham\n",
       "3218     ham\n",
       "3393     ham\n",
       "3600     ham\n",
       "1512     ham\n",
       "5475     ham\n",
       "2043     ham\n",
       "2441     ham\n",
       "3786     ham\n",
       "4948    spam\n",
       "5347     ham\n",
       "2458     ham\n",
       "2578     ham\n",
       "236      ham\n",
       "4593     ham\n",
       "1807    spam\n",
       "311      ham\n",
       "2423     ham\n",
       "1626     ham\n",
       "1579     ham\n",
       "1729     ham\n",
       "2353     ham\n",
       "3219     ham\n",
       "4110     ham\n",
       "5362     ham\n",
       "2197     ham\n",
       "3318     ham\n",
       "607     spam\n",
       "1444    spam\n",
       "846      ham\n",
       "2023    spam\n",
       "3079     ham\n",
       "5182     ham\n",
       "3317     ham\n",
       "1918     ham\n",
       "2360    spam\n",
       "4670     ham\n",
       "4095     ham\n",
       "3814     ham\n",
       "1304     ham\n",
       "563      ham\n",
       "418     spam\n",
       "3446     ham\n",
       "5470     ham\n",
       "3277     ham\n",
       "3272    spam\n",
       "3489     ham\n",
       "4819     ham\n",
       "4889     ham\n",
       "437      ham\n",
       "518     spam\n",
       "3501    spam\n",
       "2889     ham\n",
       "1020     ham\n",
       "4957     ham\n",
       "993      ham\n",
       "2550     ham\n",
       "4902     ham\n",
       "3616     ham\n",
       "3639    spam\n",
       "5008     ham\n",
       "1414    spam\n",
       "3191     ham\n",
       "5375     ham\n",
       "3974     ham\n",
       "4848     ham\n",
       "5537    spam\n",
       "2427    spam\n",
       "534      ham\n",
       "4051     ham\n",
       "1571     ham\n",
       "4305     ham\n",
       "5380     ham\n",
       "2456     ham\n",
       "4337     ham\n",
       "1477     ham\n",
       "4036    spam\n",
       "1999     ham\n",
       "4760    spam\n",
       "4659     ham\n",
       "1563     ham\n",
       "175      ham\n",
       "2539     ham\n",
       "4032     ham\n",
       "3619     ham\n",
       "3147     ham\n",
       "4241     ham\n",
       "5015     ham\n",
       "946      ham\n",
       "2445     ham\n",
       "4288     ham\n",
       "2117     ham\n",
       "5038     ham\n",
       "1542     ham\n",
       "1673    spam\n",
       "1433     ham\n",
       "616      ham\n",
       "3416     ham\n",
       "4035     ham\n",
       "1646     ham\n",
       "1395     ham\n",
       "630     spam\n",
       "955     spam\n",
       "194      ham\n",
       "4392     ham\n",
       "909      ham\n",
       "5540    spam\n",
       "1006     ham\n",
       "5080     ham\n",
       "4548     ham\n",
       "5345     ham\n",
       "4545     ham\n",
       "368     spam\n",
       "3677     ham\n",
       "4692     ham\n",
       "3531     ham\n",
       "3409    spam\n",
       "4964     ham\n",
       "2332     ham\n",
       "3954    spam\n",
       "619      ham\n",
       "1987     ham\n",
       "2358     ham\n",
       "3594     ham\n",
       "4393     ham\n",
       "216      ham\n",
       "4471     ham\n",
       "3889     ham\n",
       "5030    spam\n",
       "2000     ham\n",
       "4135     ham\n",
       "1055     ham\n",
       "3646    spam\n",
       "4774     ham\n",
       "1758     ham\n",
       "4796     ham\n",
       "4857     ham\n",
       "5311     ham\n",
       "2879    spam\n",
       "1416     ham\n",
       "3680     ham\n",
       "460      ham\n",
       "3431     ham\n",
       "1784     ham\n",
       "4570     ham\n",
       "1135     ham\n",
       "267      ham\n",
       "1892     ham\n",
       "1926     ham\n",
       "3853     ham\n",
       "3663     ham\n",
       "1521    spam\n",
       "3225     ham\n",
       "4583     ham\n",
       "817      ham\n",
       "769      ham\n",
       "4625     ham\n",
       "1837     ham\n",
       "3422    spam\n",
       "4257     ham\n",
       "2823    spam\n",
       "234      ham\n",
       "3215     ham\n",
       "4687     ham\n",
       "1291     ham\n",
       "1299     ham\n",
       "1        ham\n",
       "5092     ham\n",
       "4679     ham\n",
       "3100     ham\n",
       "2738     ham\n",
       "5109     ham\n",
       "3243     ham\n",
       "1922     ham\n",
       "210      ham\n",
       "671      ham\n",
       "2450     ham\n",
       "4096     ham\n",
       "4573     ham\n",
       "438      ham\n",
       "3435     ham\n",
       "1475     ham\n",
       "2011     ham\n",
       "4307     ham\n",
       "4206    spam\n",
       "1419     ham\n",
       "4606     ham\n",
       "880     spam\n",
       "3253     ham\n",
       "711      ham\n",
       "1335     ham\n",
       "4167     ham\n",
       "1748     ham\n",
       "1008     ham\n",
       "2886     ham\n",
       "2150     ham\n",
       "2430    spam\n",
       "2661     ham\n",
       "4557     ham\n",
       "4619     ham\n",
       "5290     ham\n",
       "5193     ham\n",
       "4739     ham\n",
       "1426     ham\n",
       "1120    spam\n",
       "321      ham\n",
       "385     spam\n",
       "4576     ham\n",
       "2318     ham\n",
       "3444     ham\n",
       "4563     ham\n",
       "2161     ham\n",
       "5321     ham\n",
       "2989     ham\n",
       "5230     ham\n",
       "1301     ham\n",
       "4608     ham\n",
       "4436    spam\n",
       "1330     ham\n",
       "4297    spam\n",
       "1399     ham\n",
       "4017     ham\n",
       "4462     ham\n",
       "3686     ham\n",
       "5198     ham\n",
       "3729     ham\n",
       "1420     ham\n",
       "2246     ham\n",
       "4512     ham\n",
       "4111     ham\n",
       "2940     ham\n",
       "2351     ham\n",
       "1721     ham\n",
       "2279     ham\n",
       "4467     ham\n",
       "1231     ham\n",
       "2517     ham\n",
       "4341     ham\n",
       "3817     ham\n",
       "396      ham\n",
       "5570     ham\n",
       "4996     ham\n",
       "4936     ham\n",
       "3211     ham\n",
       "3789    spam\n",
       "1546     ham\n",
       "4665     ham\n",
       "1535     ham\n",
       "3401    spam\n",
       "2696     ham\n",
       "5155     ham\n",
       "2060     ham\n",
       "3678     ham\n",
       "613      ham\n",
       "290      ham\n",
       "4324     ham\n",
       "186      ham\n",
       "990      ham\n",
       "4995     ham\n",
       "3185     ham\n",
       "3178     ham\n",
       "3844     ham\n",
       "4461     ham\n",
       "4926     ham\n",
       "4686     ham\n",
       "5091     ham\n",
       "5329     ham\n",
       "239      ham\n",
       "1352     ham\n",
       "650     spam\n",
       "1501     ham\n",
       "1559     ham\n",
       "1331     ham\n",
       "4622     ham\n",
       "487     spam\n",
       "2192     ham\n",
       "3111    spam\n",
       "4131     ham\n",
       "1772     ham\n",
       "730      ham\n",
       "3803     ham\n",
       "1678     ham\n",
       "4481     ham\n",
       "345      ham\n",
       "1313     ham\n",
       "3610     ham\n",
       "4982     ham\n",
       "3248     ham\n",
       "3881     ham\n",
       "4250     ham\n",
       "2645     ham\n",
       "3077     ham\n",
       "92       ham\n",
       "1333     ham\n",
       "3676     ham\n",
       "4190     ham\n",
       "3445     ham\n",
       "913      ham\n",
       "3167    spam\n",
       "794      ham\n",
       "960      ham\n",
       "4901    spam\n",
       "392      ham\n",
       "5267     ham\n",
       "268     spam\n",
       "2407     ham\n",
       "342      ham\n",
       "3069     ham\n",
       "1936     ham\n",
       "4457     ham\n",
       "4869     ham\n",
       "1899     ham\n",
       "702      ham\n",
       "1774     ham\n",
       "5130     ham\n",
       "1077     ham\n",
       "4161     ham\n",
       "2365     ham\n",
       "5462    spam\n",
       "893      ham\n",
       "695      ham\n",
       "2098     ham\n",
       "3831     ham\n",
       "2851     ham\n",
       "1958     ham\n",
       "5212     ham\n",
       "3620    spam\n",
       "2852     ham\n",
       "3085     ham\n",
       "1525     ham\n",
       "443      ham\n",
       "1650     ham\n",
       "2975     ham\n",
       "3183     ham\n",
       "2481    spam\n",
       "4303     ham\n",
       "4610     ham\n",
       "3707     ham\n",
       "3578     ham\n",
       "2778     ham\n",
       "5363     ham\n",
       "1653    spam\n",
       "430      ham\n",
       "1195     ham\n",
       "4696    spam\n",
       "4160     ham\n",
       "495      ham\n",
       "1437     ham\n",
       "1684     ham\n",
       "5559     ham\n",
       "2772     ham\n",
       "3830     ham\n",
       "2327     ham\n",
       "1959     ham\n",
       "3387     ham\n",
       "5116     ham\n",
       "1891     ham\n",
       "3491     ham\n",
       "1268     ham\n",
       "4842     ham\n",
       "5288     ham\n",
       "1739     ham\n",
       "1128     ham\n",
       "54      spam\n",
       "4500    spam\n",
       "5200    spam\n",
       "3022     ham\n",
       "1991     ham\n",
       "2756     ham\n",
       "4413     ham\n",
       "4490     ham\n",
       "4971     ham\n",
       "632      ham\n",
       "577      ham\n",
       "2983     ham\n",
       "4301     ham\n",
       "2237     ham\n",
       "2031     ham\n",
       "787      ham\n",
       "1080     ham\n",
       "4423     ham\n",
       "233      ham\n",
       "2402    spam\n",
       "3391    spam\n",
       "3308     ham\n",
       "5201    spam\n",
       "1855     ham\n",
       "3176    spam\n",
       "5129     ham\n",
       "3697     ham\n",
       "2382     ham\n",
       "784     spam\n",
       "5412     ham\n",
       "4221     ham\n",
       "5124     ham\n",
       "1675     ham\n",
       "785      ham\n",
       "4350     ham\n",
       "524      ham\n",
       "714      ham\n",
       "5034     ham\n",
       "686      ham\n",
       "4714     ham\n",
       "4371    spam\n",
       "500      ham\n",
       "3976     ham\n",
       "1621     ham\n",
       "3112     ham\n",
       "4929     ham\n",
       "857      ham\n",
       "2097     ham\n",
       "1361     ham\n",
       "292      ham\n",
       "3108     ham\n",
       "561      ham\n",
       "5304     ham\n",
       "2967     ham\n",
       "1682     ham\n",
       "93      spam\n",
       "2608     ham\n",
       "2397     ham\n",
       "661      ham\n",
       "4568     ham\n",
       "1061     ham\n",
       "3946     ham\n",
       "3104     ham\n",
       "2949     ham\n",
       "3695     ham\n",
       "1417     ham\n",
       "2850    spam\n",
       "279      ham\n",
       "3339     ham\n",
       "1703     ham\n",
       "2670    spam\n",
       "657      ham\n",
       "1438     ham\n",
       "4248    spam\n",
       "2068     ham\n",
       "1939     ham\n",
       "4109     ham\n",
       "4485     ham\n",
       "5295     ham\n",
       "5479     ham\n",
       "1956     ham\n",
       "4667     ham\n",
       "3503     ham\n",
       "389     spam\n",
       "101      ham\n",
       "861      ham\n",
       "4767     ham\n",
       "5140     ham\n",
       "3239     ham\n",
       "938      ham\n",
       "3933     ham\n",
       "4543    spam\n",
       "3940     ham\n",
       "2838     ham\n",
       "6        ham\n",
       "1063     ham\n",
       "2354    spam\n",
       "2406     ham\n",
       "482      ham\n",
       "3738     ham\n",
       "1103     ham\n",
       "224      ham\n",
       "959      ham\n",
       "1523     ham\n",
       "1637     ham\n",
       "3260    spam\n",
       "1227    spam\n",
       "436      ham\n",
       "4927     ham\n",
       "5055    spam\n",
       "4397     ham\n",
       "1043     ham\n",
       "1358     ham\n",
       "1561     ham\n",
       "4624     ham\n",
       "2079    spam\n",
       "2764     ham\n",
       "602      ham\n",
       "4316     ham\n",
       "3741     ham\n",
       "2615     ham\n",
       "3189    spam\n",
       "5232    spam\n",
       "1338     ham\n",
       "2998     ham\n",
       "4314     ham\n",
       "4966     ham\n",
       "1853    spam\n",
       "5074     ham\n",
       "3553     ham\n",
       "3722     ham\n",
       "2156     ham\n",
       "2387     ham\n",
       "3223     ham\n",
       "548      ham\n",
       "3190     ham\n",
       "4629    spam\n",
       "4657     ham\n",
       "3388     ham\n",
       "3672     ham\n",
       "2067     ham\n",
       "5012    spam\n",
       "464      ham\n",
       "568      ham\n",
       "725      ham\n",
       "2748     ham\n",
       "1818     ham\n",
       "1526     ham\n",
       "3125     ham\n",
       "395      ham\n",
       "5204     ham\n",
       "813     spam\n",
       "1143     ham\n",
       "1035     ham\n",
       "4213    spam\n",
       "1823     ham\n",
       "4077    spam\n",
       "5502     ham\n",
       "2165     ham\n",
       "1815     ham\n",
       "2294     ham\n",
       "1962     ham\n",
       "2575    spam\n",
       "773      ham\n",
       "5554     ham\n",
       "3964     ham\n",
       "4552     ham\n",
       "3026     ham\n",
       "3263     ham\n",
       "4613     ham\n",
       "201      ham\n",
       "4526     ham\n",
       "2070    spam\n",
       "1986     ham\n",
       "2610     ham\n",
       "4005     ham\n",
       "2363     ham\n",
       "5227     ham\n",
       "4256    spam\n",
       "790      ham\n",
       "139     spam\n",
       "1886     ham\n",
       "338      ham\n",
       "260      ham\n",
       "5210     ham\n",
       "719     spam\n",
       "5388     ham\n",
       "2881    spam\n",
       "376      ham\n",
       "2274     ham\n",
       "3611     ham\n",
       "3694     ham\n",
       "302      ham\n",
       "1075     ham\n",
       "5163     ham\n",
       "4351     ham\n",
       "2133    spam\n",
       "362      ham\n",
       "1565     ham\n",
       "2204     ham\n",
       "3231     ham\n",
       "953      ham\n",
       "481      ham\n",
       "3518     ham\n",
       "5478     ham\n",
       "3867     ham\n",
       "2530     ham\n",
       "5471     ham\n",
       "5016     ham\n",
       "709     spam\n",
       "4193     ham\n",
       "5408     ham\n",
       "4069    spam\n",
       "3019     ham\n",
       "130      ham\n",
       "5556     ham\n",
       "4459     ham\n",
       "3107     ham\n",
       "490      ham\n",
       "89       ham\n",
       "1635    spam\n",
       "1992     ham\n",
       "2621     ham\n",
       "351      ham\n",
       "3420    spam\n",
       "2366     ham\n",
       "4145     ham\n",
       "2453     ham\n",
       "1942    spam\n",
       "399      ham\n",
       "3327     ham\n",
       "2490     ham\n",
       "5543     ham\n",
       "1049     ham\n",
       "3084     ham\n",
       "1821     ham\n",
       "1100     ham\n",
       "3999    spam\n",
       "2931     ham\n",
       "2024     ham\n",
       "4939     ham\n",
       "3295     ham\n",
       "421      ham\n",
       "1401     ham\n",
       "3067    spam\n",
       "2083     ham\n",
       "963      ham\n",
       "1101     ham\n",
       "2774    spam\n",
       "4370     ham\n",
       "5353     ham\n",
       "435      ham\n",
       "3160     ham\n",
       "829      ham\n",
       "788     spam\n",
       "4136     ham\n",
       "2529     ham\n",
       "456      ham\n",
       "4523     ham\n",
       "2073     ham\n",
       "3319     ham\n",
       "3809     ham\n",
       "1105    spam\n",
       "3721     ham\n",
       "1770     ham\n",
       "398      ham\n",
       "5044     ham\n",
       "797     spam\n",
       "4525     ham\n",
       "4612     ham\n",
       "3777     ham\n",
       "1458    spam\n",
       "4060    spam\n",
       "1334     ham\n",
       "755      ham\n",
       "65      spam\n",
       "177      ham\n",
       "3461     ham\n",
       "4912     ham\n",
       "3016     ham\n",
       "26       ham\n",
       "525     spam\n",
       "4287     ham\n",
       "2665     ham\n",
       "4916     ham\n",
       "664      ham\n",
       "2463     ham\n",
       "1221    spam\n",
       "1742     ham\n",
       "3636     ham\n",
       "332      ham\n",
       "598     spam\n",
       "2512     ham\n",
       "4820     ham\n",
       "1459     ham\n",
       "2864     ham\n",
       "3502     ham\n",
       "739      ham\n",
       "3829     ham\n",
       "228      ham\n",
       "5305     ham\n",
       "498      ham\n",
       "7        ham\n",
       "1977     ham\n",
       "902      ham\n",
       "2544     ham\n",
       "5103     ham\n",
       "4748     ham\n",
       "1237     ham\n",
       "2275     ham\n",
       "1932     ham\n",
       "2567     ham\n",
       "949      ham\n",
       "1717     ham\n",
       "2183     ham\n",
       "2619     ham\n",
       "4380     ham\n",
       "138      ham\n",
       "5213     ham\n",
       "2017     ham\n",
       "251      ham\n",
       "4522     ham\n",
       "1090     ham\n",
       "2016     ham\n",
       "4914    spam\n",
       "2815     ham\n",
       "5156     ham\n",
       "912      ham\n",
       "5548     ham\n",
       "1281     ham\n",
       "4332     ham\n",
       "2118     ham\n",
       "911      ham\n",
       "3015     ham\n",
       "2158     ham\n",
       "3710     ham\n",
       "1089    spam\n",
       "4040     ham\n",
       "3137     ham\n",
       "936      ham\n",
       "5401     ham\n",
       "5381    spam\n",
       "1250     ham\n",
       "5040     ham\n",
       "3432     ham\n",
       "5281     ham\n",
       "3516     ham\n",
       "5242     ham\n",
       "3480     ham\n",
       "5426     ham\n",
       "4112    spam\n",
       "3262     ham\n",
       "3536     ham\n",
       "2273     ham\n",
       "1792     ham\n",
       "4400     ham\n",
       "4837     ham\n",
       "2657     ham\n",
       "4443     ham\n",
       "4363     ham\n",
       "5286     ham\n",
       "5358     ham\n",
       "2388     ham\n",
       "4018     ham\n",
       "892      ham\n",
       "5467    spam\n",
       "4106     ham\n",
       "2727     ham\n",
       "1725     ham\n",
       "5369     ham\n",
       "2051     ham\n",
       "5022     ham\n",
       "3624     ham\n",
       "4951     ham\n",
       "2471     ham\n",
       "2046     ham\n",
       "5026     ham\n",
       "403      ham\n",
       "5167     ham\n",
       "50       ham\n",
       "3332     ham\n",
       "3398     ham\n",
       "4444     ham\n",
       "558      ham\n",
       "3510     ham\n",
       "2819     ham\n",
       "4556     ham\n",
       "1151     ham\n",
       "9       spam\n",
       "1707     ham\n",
       "4836     ham\n",
       "1614     ham\n",
       "1071     ham\n",
       "5474     ham\n",
       "4292     ham\n",
       "5298     ham\n",
       "716      ham\n",
       "1896     ham\n",
       "5054     ham\n",
       "2123     ham\n",
       "318      ham\n",
       "5466    spam\n",
       "1672     ham\n",
       "3315     ham\n",
       "427      ham\n",
       "2641     ham\n",
       "546      ham\n",
       "262      ham\n",
       "254      ham\n",
       "666      ham\n",
       "2472     ham\n",
       "171      ham\n",
       "1176     ham\n",
       "4852     ham\n",
       "1482     ham\n",
       "1906     ham\n",
       "3347     ham\n",
       "4021     ham\n",
       "1900     ham\n",
       "693      ham\n",
       "4762     ham\n",
       "4851     ham\n",
       "5415     ham\n",
       "4063     ham\n",
       "2115    spam\n",
       "3979     ham\n",
       "5161     ham\n",
       "781      ham\n",
       "3092    spam\n",
       "4580     ham\n",
       "2459     ham\n",
       "541     spam\n",
       "3782     ham\n",
       "4524     ham\n",
       "4713     ham\n",
       "5416     ham\n",
       "882      ham\n",
       "3549     ham\n",
       "3878     ham\n",
       "4306     ham\n",
       "5503     ham\n",
       "4286     ham\n",
       "1171     ham\n",
       "2948     ham\n",
       "1329     ham\n",
       "5411     ham\n",
       "5385     ham\n",
       "75       ham\n",
       "3201     ham\n",
       "4252     ham\n",
       "3884     ham\n",
       "2194     ham\n",
       "1466    spam\n",
       "5173     ham\n",
       "3287     ham\n",
       "3690     ham\n",
       "945      ham\n",
       "4441     ham\n",
       "5445     ham\n",
       "842      ham\n",
       "2872     ham\n",
       "2682     ham\n",
       "4200    spam\n",
       "2997     ham\n",
       "3934     ham\n",
       "225     spam\n",
       "4382     ham\n",
       "1856     ham\n",
       "4338     ham\n",
       "845      ham\n",
       "572      ham\n",
       "4587    spam\n",
       "4727     ham\n",
       "3247     ham\n",
       "154      ham\n",
       "476      ham\n",
       "3350     ham\n",
       "4853     ham\n",
       "1690     ham\n",
       "278      ham\n",
       "3402     ham\n",
       "5525     ham\n",
       "1087     ham\n",
       "3113     ham\n",
       "382      ham\n",
       "1099     ham\n",
       "3159     ham\n",
       "3521     ham\n",
       "2918     ham\n",
       "5498     ham\n",
       "918      ham\n",
       "3972    spam\n",
       "3282     ham\n",
       "4855     ham\n",
       "4427     ham\n",
       "297      ham\n",
       "5036     ham\n",
       "527     spam\n",
       "4873     ham\n",
       "442      ham\n",
       "2120     ham\n",
       "1138     ham\n",
       "4844     ham\n",
       "2987    spam\n",
       "4058     ham\n",
       "3802     ham\n",
       "2374    spam\n",
       "5557     ham\n",
       "5316     ham\n",
       "1836     ham\n",
       "2584     ham\n",
       "2008     ham\n",
       "3756     ham\n",
       "47       ham\n",
       "2201     ham\n",
       "3371     ham\n",
       "397      ham\n",
       "1507    spam\n",
       "2804    spam\n",
       "2692     ham\n",
       "4591     ham\n",
       "4569     ham\n",
       "3073     ham\n",
       "4934     ham\n",
       "986      ham\n",
       "5179     ham\n",
       "5084     ham\n",
       "4164     ham\n",
       "5187     ham\n",
       "237      ham\n",
       "2119    spam\n",
       "4437     ham\n",
       "2800     ham\n",
       "1104     ham\n",
       "3162     ham\n",
       "802      ham\n",
       "4786    spam\n",
       "5335     ham\n",
       "4607     ham\n",
       "3305     ham\n",
       "5545     ham\n",
       "1737     ham\n",
       "3949     ham\n",
       "2912     ham\n",
       "4874     ham\n",
       "3704     ham\n",
       "34      spam\n",
       "2245     ham\n",
       "4224     ham\n",
       "4414     ham\n",
       "3447     ham\n",
       "564     spam\n",
       "4595     ham\n",
       "74       ham\n",
       "855      ham\n",
       "309     spam\n",
       "2702     ham\n",
       "282      ham\n",
       "2910    spam\n",
       "2873     ham\n",
       "547      ham\n",
       "4381     ham\n",
       "1570     ham\n",
       "1158     ham\n",
       "1680     ham\n",
       "720      ham\n",
       "291      ham\n",
       "540      ham\n",
       "2860     ham\n",
       "2232     ham\n",
       "1036     ham\n",
       "3255     ham\n",
       "1047     ham\n",
       "2573     ham\n",
       "3076     ham\n",
       "2315     ham\n",
       "60       ham\n",
       "1599     ham\n",
       "5547    spam\n",
       "1189     ham\n",
       "5126     ham\n",
       "5137    spam\n",
       "2443     ham\n",
       "3657     ham\n",
       "535      ham\n",
       "4434     ham\n",
       "4986     ham\n",
       "3099     ham\n",
       "3551     ham\n",
       "581      ham\n",
       "3172     ham\n",
       "195      ham\n",
       "1263    spam\n",
       "172      ham\n",
       "3473     ham\n",
       "4242     ham\n",
       "924      ham\n",
       "1013     ham\n",
       "4249    spam\n",
       "1173     ham\n",
       "1562     ham\n",
       "1641     ham\n",
       "3587    spam\n",
       "1430    spam\n",
       "3119     ham\n",
       "2992    spam\n",
       "4184     ham\n",
       "4251     ham\n",
       "3027     ham\n",
       "2779    spam\n",
       "1239     ham\n",
       "3902     ham\n",
       "415     spam\n",
       "4260     ham\n",
       "982      ham\n",
       "1164     ham\n",
       "1779     ham\n",
       "5564     ham\n",
       "2861     ham\n",
       "586      ham\n",
       "595      ham\n",
       "1811     ham\n",
       "812      ham\n",
       "1949     ham\n",
       "5238     ham\n",
       "1167     ham\n",
       "1930    spam\n",
       "220      ham\n",
       "1065     ham\n",
       "5222     ham\n",
       "1692     ham\n",
       "5473     ham\n",
       "2560     ham\n",
       "2013     ham\n",
       "4446     ham\n",
       "774      ham\n",
       "305     spam\n",
       "439      ham\n",
       "713     spam\n",
       "5098    spam\n",
       "2637     ham\n",
       "1024     ham\n",
       "3152     ham\n",
       "1082     ham\n",
       "4406     ham\n",
       "2293     ham\n",
       "734      ham\n",
       "1674    spam\n",
       "2708    spam\n",
       "3693     ham\n",
       "4581     ham\n",
       "3522     ham\n",
       "3479     ham\n",
       "2113    spam\n",
       "1610     ham\n",
       "1643     ham\n",
       "1219     ham\n",
       "1604     ham\n",
       "357     spam\n",
       "3087     ham\n",
       "530      ham\n",
       "3396     ham\n",
       "5364    spam\n",
       "1093     ham\n",
       "1765    spam\n",
       "2444     ham\n",
       "1935     ham\n",
       "985      ham\n",
       "3296     ham\n",
       "4163     ham\n",
       "4465     ham\n",
       "2337     ham\n",
       "2640     ham\n",
       "4098     ham\n",
       "4516     ham\n",
       "2753     ham\n",
       "3808     ham\n",
       "4694     ham\n",
       "1288     ham\n",
       "2887     ham\n",
       "137      ham\n",
       "973      ham\n",
       "1648     ham\n",
       "2938     ham\n",
       "615      ham\n",
       "4183    spam\n",
       "3986     ham\n",
       "1858     ham\n",
       "4633     ham\n",
       "4746    spam\n",
       "3772     ham\n",
       "1711     ham\n",
       "2268     ham\n",
       "5427    spam\n",
       "5372     ham\n",
       "2424     ham\n",
       "4090     ham\n",
       "2635     ham\n",
       "3585    spam\n",
       "1366    spam\n",
       "414      ham\n",
       "4169    spam\n",
       "2330     ham\n",
       "3731     ham\n",
       "3507     ham\n",
       "2719    spam\n",
       "4128     ham\n",
       "1040     ham\n",
       "4520     ham\n",
       "3378     ham\n",
       "3290    spam\n",
       "3812     ham\n",
       "4821    spam\n",
       "508      ham\n",
       "3665     ham\n",
       "4604     ham\n",
       "2448     ham\n",
       "1781    spam\n",
       "4535     ham\n",
       "4953    spam\n",
       "2698     ham\n",
       "5359     ham\n",
       "4117     ham\n",
       "543      ham\n",
       "4909     ham\n",
       "4177     ham\n",
       "223      ham\n",
       "4356     ham\n",
       "3687     ham\n",
       "1402     ham\n",
       "1872     ham\n",
       "3408     ham\n",
       "2136     ham\n",
       "180      ham\n",
       "5206     ham\n",
       "2173     ham\n",
       "2740     ham\n",
       "1322     ham\n",
       "3032     ham\n",
       "4877    spam\n",
       "539      ham\n",
       "289      ham\n",
       "5442     ham\n",
       "975      ham\n",
       "2404     ham\n",
       "3382    spam\n",
       "3256     ham\n",
       "3880     ham\n",
       "3628     ham\n",
       "41       ham\n",
       "5402     ham\n",
       "3210     ham\n",
       "3641     ham\n",
       "3876     ham\n",
       "4156    spam\n",
       "4638     ham\n",
       "3511     ham\n",
       "5211     ham\n",
       "876     spam\n",
       "2383     ham\n",
       "1391     ham\n",
       "506      ham\n",
       "4207     ham\n",
       "1014     ham\n",
       "3372     ham\n",
       "387      ham\n",
       "3771     ham\n",
       "307      ham\n",
       "1336     ham\n",
       "1863     ham\n",
       "3798     ham\n",
       "4089     ham\n",
       "2854     ham\n",
       "1255     ham\n",
       "4199    spam\n",
       "340      ham\n",
       "1801     ham\n",
       "5146     ham\n",
       "1955     ham\n",
       "4885     ham\n",
       "4504     ham\n",
       "2004     ham\n",
       "2595     ham\n",
       "747      ham\n",
       "3801    spam\n",
       "4234     ham\n",
       "2053    spam\n",
       "5057     ham\n",
       "1503     ham\n",
       "4824     ham\n",
       "4046     ham\n",
       "1780    spam\n",
       "4700     ham\n",
       "765      ham\n",
       "4282     ham\n",
       "925      ham\n",
       "856     spam\n",
       "3894     ham\n",
       "5425     ham\n",
       "1270     ham\n",
       "4801     ham\n",
       "3833     ham\n",
       "1114     ham\n",
       "5258     ham\n",
       "3660     ham\n",
       "751     spam\n",
       "2703     ham\n",
       "4645     ham\n",
       "4016    spam\n",
       "151      ham\n",
       "1032     ham\n",
       "2508     ham\n",
       "3865     ham\n",
       "346      ham\n",
       "4344     ham\n",
       "2630     ham\n",
       "1670     ham\n",
       "706      ham\n",
       "5174     ham\n",
       "2675     ham\n",
       "2943     ham\n",
       "1746     ham\n",
       "1400     ham\n",
       "1017    spam\n",
       "4329    spam\n",
       "1649     ham\n",
       "2240     ham\n",
       "2971     ham\n",
       "1502    spam\n",
       "87       ham\n",
       "2699    spam\n",
       "521      ham\n",
       "5039     ham\n",
       "1556     ham\n",
       "4072     ham\n",
       "3643     ham\n",
       "3037     ham\n",
       "2855     ham\n",
       "5028    spam\n",
       "1201     ham\n",
       "2135     ham\n",
       "4432     ham\n",
       "2927     ham\n",
       "5332     ham\n",
       "3321     ham\n",
       "5439     ham\n",
       "2735     ham\n",
       "4038     ham\n",
       "1142    spam\n",
       "2785     ham\n",
       "10       ham\n",
       "2963     ham\n",
       "4215     ham\n",
       "3861     ham\n",
       "3892     ham\n",
       "4711     ham\n",
       "2296     ham\n",
       "4560     ham\n",
       "2671     ham\n",
       "1845     ham\n",
       "2099     ham\n",
       "569      ham\n",
       "4245     ham\n",
       "4677     ham\n",
       "4281    spam\n",
       "2276     ham\n",
       "1408     ham\n",
       "5383     ham\n",
       "604      ham\n",
       "3897    spam\n",
       "3903     ham\n",
       "5160     ham\n",
       "5132     ham\n",
       "1332     ham\n",
       "1647     ham\n",
       "2701     ham\n",
       "4703     ham\n",
       "3286     ham\n",
       "688      ham\n",
       "822      ham\n",
       "5202     ham\n",
       "4084     ham\n",
       "2984     ham\n",
       "1677     ham\n",
       "1149     ham\n",
       "3080     ham\n",
       "3498     ham\n",
       "1493     ham\n",
       "3601     ham\n",
       "2114     ham\n",
       "5497    spam\n",
       "1323     ham\n",
       "5394     ham\n",
       "4798    spam\n",
       "4185     ham\n",
       "5309     ham\n",
       "4044     ham\n",
       "2087     ham\n",
       "917      ham\n",
       "3180     ham\n",
       "1601     ham\n",
       "4769     ham\n",
       "559      ham\n",
       "2945    spam\n",
       "5025     ham\n",
       "707      ham\n",
       "4309     ham\n",
       "583     spam\n",
       "1208     ham\n",
       "4924     ham\n",
       "422     spam\n",
       "2633     ham\n",
       "3407     ham\n",
       "875      ham\n",
       "4994     ham\n",
       "3379     ham\n",
       "5019     ham\n",
       "4220     ham\n",
       "1566     ham\n",
       "4680     ham\n",
       "1183     ham\n",
       "227     spam\n",
       "826      ham\n",
       "5050     ham\n",
       "4043     ham\n",
       "2321     ham\n",
       "4789     ham\n",
       "1636     ham\n",
       "2828     ham\n",
       "3901     ham\n",
       "4864    spam\n",
       "3005    spam\n",
       "1190     ham\n",
       "5386     ham\n",
       "1374    spam\n",
       "1569     ham\n",
       "3661     ham\n",
       "2134     ham\n",
       "3588     ham\n",
       "1808     ham\n",
       "825      ham\n",
       "3866     ham\n",
       "3066     ham\n",
       "2480    spam\n",
       "499      ham\n",
       "4799     ham\n",
       "4144    spam\n",
       "816      ham\n",
       "1316     ham\n",
       "3618     ham\n",
       "2533     ham\n",
       "3883     ham\n",
       "509      ham\n",
       "146      ham\n",
       "5313     ham\n",
       "5209     ham\n",
       "629     spam\n",
       "1536    spam\n",
       "5344     ham\n",
       "1196    spam\n",
       "2978     ham\n",
       "470      ham\n",
       "4155     ham\n",
       "3078     ham\n",
       "1789     ham\n",
       "4029     ham\n",
       "4609     ham\n",
       "204      ham\n",
       "2822     ham\n",
       "2005     ham\n",
       "5170     ham\n",
       "3602     ham\n",
       "5520     ham\n",
       "2650     ham\n",
       "2747     ham\n",
       "2352    spam\n",
       "1754     ham\n",
       "1215     ham\n",
       "3514     ham\n",
       "4932     ham\n",
       "4515     ham\n",
       "1451     ham\n",
       "2215     ham\n",
       "3128     ham\n",
       "1903     ham\n",
       "979      ham\n",
       "549      ham\n",
       "5327     ham\n",
       "4369     ham\n",
       "2266     ham\n",
       "4584    spam\n",
       "1425     ham\n",
       "4099     ham\n",
       "576     spam\n",
       "2807     ham\n",
       "1452     ham\n",
       "4954     ham\n",
       "445      ham\n",
       "3568    spam\n",
       "5500     ham\n",
       "627      ham\n",
       "347      ham\n",
       "341      ham\n",
       "4480     ham\n",
       "5376     ham\n",
       "777      ham\n",
       "4134    spam\n",
       "3854     ham\n",
       "5186     ham\n",
       "5233     ham\n",
       "303      ham\n",
       "926      ham\n",
       "4422     ham\n",
       "675      ham\n",
       "4652    spam\n",
       "2308    spam\n",
       "584      ham\n",
       "2012     ham\n",
       "3858     ham\n",
       "5123     ham\n",
       "3793     ham\n",
       "2869     ham\n",
       "241      ham\n",
       "1862     ham\n",
       "1479     ham\n",
       "2014    spam\n",
       "3733     ham\n",
       "786      ham\n",
       "5441     ham\n",
       "170      ham\n",
       "2536     ham\n",
       "2969     ham\n",
       "896      ham\n",
       "5162     ham\n",
       "2775     ham\n",
       "1376     ham\n",
       "4093     ham\n",
       "3527     ham\n",
       "3683     ham\n",
       "4030     ham\n",
       "477      ham\n",
       "5464     ham\n",
       "337      ham\n",
       "1895    spam\n",
       "320      ham\n",
       "2129     ham\n",
       "4795     ham\n",
       "4541     ham\n",
       "635     spam\n",
       "620      ham\n",
       "3275     ham\n",
       "5076    spam\n",
       "1658     ham\n",
       "2102     ham\n",
       "3193     ham\n",
       "2186     ham\n",
       "4041     ham\n",
       "4778     ham\n",
       "3577     ham\n",
       "3459     ham\n",
       "4319     ham\n",
       "3645     ham\n",
       "2794     ham\n",
       "681      ham\n",
       "2312    spam\n",
       "1709     ham\n",
       "2298     ham\n",
       "4355    spam\n",
       "1261     ham\n",
       "4211     ham\n",
       "3767     ham\n",
       "1950     ham\n",
       "5047     ham\n",
       "4075     ham\n",
       "22       ham\n",
       "735      ham\n",
       "536      ham\n",
       "4102    spam\n",
       "2769     ham\n",
       "1585     ham\n",
       "3495    spam\n",
       "1349     ham\n",
       "866     spam\n",
       "1127     ham\n",
       "5399     ham\n",
       "5432     ham\n",
       "122      ham\n",
       "5405     ham\n",
       "2831     ham\n",
       "5236     ham\n",
       "1767    spam\n",
       "3836     ham\n",
       "4917     ham\n",
       "3558     ham\n",
       "1607     ham\n",
       "2095    spam\n",
       "4385     ham\n",
       "5237    spam\n",
       "2421     ham\n",
       "1797     ham\n",
       "4969     ham\n",
       "4107     ham\n",
       "1506     ham\n",
       "2557     ham\n",
       "4640     ham\n",
       "2474     ham\n",
       "3434     ham\n",
       "167     spam\n",
       "1193     ham\n",
       "2937     ham\n",
       "1220     ham\n",
       "3041     ham\n",
       "1194    spam\n",
       "2627     ham\n",
       "2364    spam\n",
       "4146     ham\n",
       "78       ham\n",
       "1698     ham\n",
       "4189     ham\n",
       "2476     ham\n",
       "3307     ham\n",
       "4346     ham\n",
       "2755     ham\n",
       "2190     ham\n",
       "370      ham\n",
       "485      ham\n",
       "4527    spam\n",
       "520      ham\n",
       "571      ham\n",
       "2647     ham\n",
       "3329     ham\n",
       "2281     ham\n",
       "1943     ham\n",
       "2816     ham\n",
       "947     spam\n",
       "5120    spam\n",
       "2356     ham\n",
       "5106     ham\n",
       "1489     ham\n",
       "3353     ham\n",
       "4052     ham\n",
       "1096     ham\n",
       "2124    spam\n",
       "3675    spam\n",
       "2655     ham\n",
       "5151     ham\n",
       "3266    spam\n",
       "4304     ham\n",
       "2824     ham\n",
       "510      ham\n",
       "1861     ham\n",
       "3483    spam\n",
       "1359     ham\n",
       "1107     ham\n",
       "533      ham\n",
       "4261     ham\n",
       "2426     ham\n",
       "3228     ham\n",
       "2168     ham\n",
       "2668     ham\n",
       "413      ham\n",
       "5229     ham\n",
       "5003     ham\n",
       "3821     ham\n",
       "5339     ham\n",
       "2731     ham\n",
       "3118     ham\n",
       "1730     ham\n",
       "4974     ham\n",
       "1002    spam\n",
       "5101     ham\n",
       "3390     ham\n",
       "5142     ham\n",
       "4387     ham\n",
       "883      ham\n",
       "2736     ham\n",
       "3361     ham\n",
       "1688    spam\n",
       "1347     ham\n",
       "3457     ham\n",
       "1708     ham\n",
       "3466     ham\n",
       "160     spam\n",
       "670      ham\n",
       "1266     ham\n",
       "3813     ham\n",
       "3823     ham\n",
       "2679     ham\n",
       "1551     ham\n",
       "2325     ham\n",
       "5000     ham\n",
       "5292    spam\n",
       "4273     ham\n",
       "5049     ham\n",
       "4007     ham\n",
       "3851     ham\n",
       "1365     ham\n",
       "3759     ham\n",
       "2225     ham\n",
       "4722     ham\n",
       "5325     ham\n",
       "363      ham\n",
       "2601     ham\n",
       "2081     ham\n",
       "2359     ham\n",
       "2333     ham\n",
       "4705     ham\n",
       "614      ham\n",
       "1760     ham\n",
       "91       ham\n",
       "1644     ham\n",
       "4631     ham\n",
       "4086    spam\n",
       "2563     ham\n",
       "1964     ham\n",
       "3508     ham\n",
       "4508     ham\n",
       "2001     ham\n",
       "3935     ham\n",
       "5009     ham\n",
       "2966     ham\n",
       "3846     ham\n",
       "1661     ham\n",
       "2401     ham\n",
       "4981     ham\n",
       "142      ham\n",
       "3091     ham\n",
       "3644     ham\n",
       "258      ham\n",
       "1496     ham\n",
       "1602     ham\n",
       "4716     ham\n",
       "2741     ham\n",
       "3969     ham\n",
       "649      ham\n",
       "2323     ham\n",
       "4632     ham\n",
       "970      ham\n",
       "3251     ham\n",
       "3072     ham\n",
       "1305     ham\n",
       "3730     ham\n",
       "4088    spam\n",
       "4425     ham\n",
       "3090     ham\n",
       "3007     ham\n",
       "5318     ham\n",
       "3837     ham\n",
       "4661     ham\n",
       "2284     ham\n",
       "2500     ham\n",
       "1782     ham\n",
       "1363     ham\n",
       "1468     ham\n",
       "3056    spam\n",
       "1945     ham\n",
       "3909     ham\n",
       "4133     ham\n",
       "270     spam\n",
       "5506     ham\n",
       "5062     ham\n",
       "1696     ham\n",
       "4888    spam\n",
       "2449     ham\n",
       "1911     ham\n",
       "3581     ham\n",
       "1819     ham\n",
       "406      ham\n",
       "1805     ham\n",
       "4734     ham\n",
       "2933     ham\n",
       "4510     ham\n",
       "3187     ham\n",
       "4956     ham\n",
       "5323     ham\n",
       "4050     ham\n",
       "3186     ham\n",
       "1544    spam\n",
       "463     spam\n",
       "1223     ham\n",
       "4841    spam\n",
       "4495     ham\n",
       "1091    spam\n",
       "691      ham\n",
       "1241     ham\n",
       "103      ham\n",
       "4066     ham\n",
       "1631     ham\n",
       "3583     ham\n",
       "683      ham\n",
       "3249     ham\n",
       "3656     ham\n",
       "3926     ham\n",
       "597      ham\n",
       "3923     ham\n",
       "4115     ham\n",
       "4399     ham\n",
       "2818    spam\n",
       "2695     ham\n",
       "4693     ham\n",
       "2080     ham\n",
       "199      ham\n",
       "3668     ham\n",
       "4312     ham\n",
       "2121     ham\n",
       "323      ham\n",
       "1813     ham\n",
       "2350     ham\n",
       "39       ham\n",
       "2672     ham\n",
       "68      spam\n",
       "2410     ham\n",
       "2182     ham\n",
       "3603     ham\n",
       "679      ham\n",
       "5177     ham\n",
       "4546     ham\n",
       "2202     ham\n",
       "2528     ham\n",
       "365      ham\n",
       "733      ham\n",
       "3942    spam\n",
       "2341     ham\n",
       "2071    spam\n",
       "4846     ham\n",
       "954      ham\n",
       "2673     ham\n",
       "287      ham\n",
       "3226     ham\n",
       "3031     ham\n",
       "3064    spam\n",
       "5482    spam\n",
       "2549     ham\n",
       "2167     ham\n",
       "4725    spam\n",
       "3692     ham\n",
       "2425     ham\n",
       "1581     ham\n",
       "2833     ham\n",
       "2028     ham\n",
       "2062     ham\n",
       "3891    spam\n",
       "2609     ham\n",
       "3958     ham\n",
       "4614     ham\n",
       "2556    spam\n",
       "3043     ham\n",
       "2311    spam\n",
       "5194     ham\n",
       "2686    spam\n",
       "4142     ham\n",
       "2066     ham\n",
       "1057     ham\n",
       "793      ham\n",
       "4031     ham\n",
       "4738     ham\n",
       "1732     ham\n",
       "4149    spam\n",
       "1097    spam\n",
       "1597    spam\n",
       "1293     ham\n",
       "950      ham\n",
       "3929     ham\n",
       "4236    spam\n",
       "3834     ham\n",
       "2056     ham\n",
       "2130     ham\n",
       "5436     ham\n",
       "828      ham\n",
       "5214    spam\n",
       "2936     ham\n",
       "4555     ham\n",
       "2982     ham\n",
       "722      ham\n",
       "5434     ham\n",
       "5536     ham\n",
       "3240     ham\n",
       "2888     ham\n",
       "1595     ham\n",
       "4494     ham\n",
       "3586     ham\n",
       "4759    spam\n",
       "764      ham\n",
       "4571    spam\n",
       "2591     ham\n",
       "2525    spam\n",
       "1592     ham\n",
       "3096     ham\n",
       "5118     ham\n",
       "1421     ham\n",
       "654      ham\n",
       "3341     ham\n",
       "283      ham\n",
       "3650     ham\n",
       "4784     ham\n",
       "2259     ham\n",
       "2026     ham\n",
       "5450     ham\n",
       "4062     ham\n",
       "5159     ham\n",
       "1445     ham\n",
       "981      ham\n",
       "3810     ham\n",
       "1153     ham\n",
       "3414     ham\n",
       "674      ham\n",
       "468      ham\n",
       "1317     ham\n",
       "3584     ham\n",
       "429      ham\n",
       "3651     ham\n",
       "1555     ham\n",
       "1129    spam\n",
       "1210     ham\n",
       "916      ham\n",
       "166      ham\n",
       "3059    spam\n",
       "4704     ham\n",
       "3888     ham\n",
       "5261     ham\n",
       "3765     ham\n",
       "2494     ham\n",
       "1000     ham\n",
       "1178     ham\n",
       "56      spam\n",
       "3020     ham\n",
       "208      ham\n",
       "2111     ham\n",
       "4057     ham\n",
       "1307    spam\n",
       "1440     ham\n",
       "425      ham\n",
       "697      ham\n",
       "5535     ham\n",
       "1265     ham\n",
       "4195     ham\n",
       "5051     ham\n",
       "1593     ham\n",
       "5303     ham\n",
       "2301     ham\n",
       "492     spam\n",
       "961      ham\n",
       "1860     ham\n",
       "4103     ham\n",
       "4959     ham\n",
       "3035     ham\n",
       "978      ham\n",
       "5131     ham\n",
       "3917     ham\n",
       "819      ham\n",
       "2866     ham\n",
       "1826     ham\n",
       "4087     ham\n",
       "4308     ham\n",
       "1467     ham\n",
       "4708     ham\n",
       "621      ham\n",
       "4474     ham\n",
       "4265     ham\n",
       "3048     ham\n",
       "1778    spam\n",
       "3938     ham\n",
       "336      ham\n",
       "3737     ham\n",
       "3593     ham\n",
       "1083     ham\n",
       "2607     ham\n",
       "4895     ham\n",
       "390      ham\n",
       "737      ham\n",
       "113      ham\n",
       "1068     ham\n",
       "937      ham\n",
       "2299     ham\n",
       "1873     ham\n",
       "5135     ham\n",
       "1015     ham\n",
       "2883     ham\n",
       "3291     ham\n",
       "257      ham\n",
       "3778    spam\n",
       "1339     ham\n",
       "1152     ham\n",
       "2264    spam\n",
       "992      ham\n",
       "3438     ham\n",
       "4100     ham\n",
       "2558    spam\n",
       "1009     ham\n",
       "3696     ham\n",
       "3504     ham\n",
       "526      ham\n",
       "4475    spam\n",
       "4678     ham\n",
       "132      ham\n",
       "2462     ham\n",
       "35       ham\n",
       "441      ham\n",
       "64       ham\n",
       "2029     ham\n",
       "1668     ham\n",
       "4876     ham\n",
       "1282     ham\n",
       "2175     ham\n",
       "638      ham\n",
       "3635     ham\n",
       "1224     ham\n",
       "3951     ham\n",
       "5172     ham\n",
       "1218     ham\n",
       "1598    spam\n",
       "2725     ham\n",
       "2836     ham\n",
       "4276     ham\n",
       "4379     ham\n",
       "767      ham\n",
       "2572     ham\n",
       "4672     ham\n",
       "1294     ham\n",
       "4915     ham\n",
       "4325     ham\n",
       "1108     ham\n",
       "1659    spam\n",
       "1744     ham\n",
       "1278     ham\n",
       "3157     ham\n",
       "4139     ham\n",
       "2959    spam\n",
       "3862    spam\n",
       "4724     ham\n",
       "2952     ham\n",
       "129      ham\n",
       "2700     ham\n",
       "2255     ham\n",
       "27       ham\n",
       "3484     ham\n",
       "4689     ham\n",
       "4076     ham\n",
       "452      ham\n",
       "1234     ham\n",
       "5013     ham\n",
       "1719     ham\n",
       "5310     ham\n",
       "3682     ham\n",
       "459      ham\n",
       "2391     ham\n",
       "680      ham\n",
       "2009     ham\n",
       "3922     ham\n",
       "2466     ham\n",
       "1747     ham\n",
       "3649     ham\n",
       "1954     ham\n",
       "361      ham\n",
       "1804     ham\n",
       "4315     ham\n",
       "3754     ham\n",
       "202      ham\n",
       "934      ham\n",
       "4928     ham\n",
       "5250    spam\n",
       "964      ham\n",
       "124      ham\n",
       "5021     ham\n",
       "3025     ham\n",
       "5279     ham\n",
       "1965     ham\n",
       "2972     ham\n",
       "4383     ham\n",
       "2515     ham\n",
       "4586    spam\n",
       "4585     ham\n",
       "446      ham\n",
       "4513     ham\n",
       "2996     ham\n",
       "647      ham\n",
       "4479     ham\n",
       "2452     ham\n",
       "3323     ham\n",
       "4198    spam\n",
       "1757     ham\n",
       "1588     ham\n",
       "935     spam\n",
       "1450     ham\n",
       "4637     ham\n",
       "4486     ham\n",
       "1353     ham\n",
       "3900     ham\n",
       "3138     ham\n",
       "1188     ham\n",
       "217      ham\n",
       "1415     ham\n",
       "4715     ham\n",
       "3541     ham\n",
       "3440     ham\n",
       "5245     ham\n",
       "877      ham\n",
       "3294     ham\n",
       "3993     ham\n",
       "2022     ham\n",
       "5014     ham\n",
       "66       ham\n",
       "3930     ham\n",
       "1481     ham\n",
       "4973     ham\n",
       "736      ham\n",
       "1846     ham\n",
       "272      ham\n",
       "1490     ham\n",
       "3429     ham\n",
       "4826     ham\n",
       "5451     ham\n",
       "5524    spam\n",
       "4564     ham\n",
       "1944     ham\n",
       "660     spam\n",
       "1446     ham\n",
       "2801     ham\n",
       "4534    spam\n",
       "288      ham\n",
       "1776     ham\n",
       "1357     ham\n",
       "782      ham\n",
       "3841     ham\n",
       "3925     ham\n",
       "1978    spam\n",
       "3712     ham\n",
       "226      ham\n",
       "760      ham\n",
       "3163     ham\n",
       "514      ham\n",
       "727      ham\n",
       "5319     ham\n",
       "1605     ham\n",
       "5429     ham\n",
       "3097     ham\n",
       "5433     ham\n",
       "2917     ham\n",
       "2891     ham\n",
       "4181     ham\n",
       "908      ham\n",
       "800      ham\n",
       "768      ham\n",
       "193      ham\n",
       "663      ham\n",
       "742      ham\n",
       "3599     ham\n",
       "4712     ham\n",
       "1454     ham\n",
       "612      ham\n",
       "3950     ham\n",
       "4045     ham\n",
       "1870     ham\n",
       "4326     ham\n",
       "401     spam\n",
       "3540     ham\n",
       "4451     ham\n",
       "849      ham\n",
       "4785     ham\n",
       "3921    spam\n",
       "1728     ham\n",
       "374      ham\n",
       "4365     ham\n",
       "2935     ham\n",
       "537      ham\n",
       "4492     ham\n",
       "3735     ham\n",
       "1007    spam\n",
       "5333     ham\n",
       "4429     ham\n",
       "409      ham\n",
       "578      ham\n",
       "692      ham\n",
       "1611     ham\n",
       "2734     ham\n",
       "5446     ham\n",
       "3757     ham\n",
       "4639     ham\n",
       "655      ham\n",
       "444      ham\n",
       "3871     ham\n",
       "1829     ham\n",
       "3165     ham\n",
       "5308     ham\n",
       "1228     ham\n",
       "4194     ham\n",
       "3385    spam\n",
       "2286     ham\n",
       "3607     ham\n",
       "3133     ham\n",
       "590      ham\n",
       "2906     ham\n",
       "1575     ham\n",
       "478      ham\n",
       "3129     ham\n",
       "4816     ham\n",
       "4908     ham\n",
       "2656     ham\n",
       "2396     ham\n",
       "2140     ham\n",
       "3124     ham\n",
       "5185     ham\n",
       "2660     ham\n",
       "1871     ham\n",
       "4143     ham\n",
       "3283     ham\n",
       "2620    spam\n",
       "465      ham\n",
       "743      ham\n",
       "2751     ham\n",
       "4904     ham\n",
       "182      ham\n",
       "3747     ham\n",
       "242      ham\n",
       "2716     ham\n",
       "1394     ham\n",
       "1053     ham\n",
       "5320     ham\n",
       "653      ham\n",
       "148      ham\n",
       "708      ham\n",
       "369      ham\n",
       "23       ham\n",
       "3312     ham\n",
       "1285     ham\n",
       "1957     ham\n",
       "2260     ham\n",
       "1532     ham\n",
       "1436     ham\n",
       "919      ham\n",
       "1199     ham\n",
       "2216     ham\n",
       "5048     ham\n",
       "469      ham\n",
       "5367     ham\n",
       "1192     ham\n",
       "106      ham\n",
       "1484     ham\n",
       "4579    spam\n",
       "350      ham\n",
       "1509     ham\n",
       "1260     ham\n",
       "48       ham\n",
       "238      ham\n",
       "712      ham\n",
       "1443     ham\n",
       "5175     ham\n",
       "5499     ham\n",
       "4682     ham\n",
       "4417     ham\n",
       "4390     ham\n",
       "2663    spam\n",
       "2718     ham\n",
       "2613     ham\n",
       "4636     ham\n",
       "2511     ham\n",
       "900     spam\n",
       "3987     ham\n",
       "4137     ham\n",
       "4732     ham\n",
       "3608     ham\n",
       "1931     ham\n",
       "5224     ham\n",
       "5551     ham\n",
       "3033     ham\n",
       "2771     ham\n",
       "4186     ham\n",
       "5348     ham\n",
       "3961     ham\n",
       "3847     ham\n",
       "2254     ham\n",
       "2125     ham\n",
       "30       ham\n",
       "2306     ham\n",
       "3206     ham\n",
       "1226     ham\n",
       "4002     ham\n",
       "2329     ham\n",
       "3887     ham\n",
       "173      ham\n",
       "2676     ham\n",
       "3931     ham\n",
       "5280     ham\n",
       "3241     ham\n",
       "859      ham\n",
       "1972     ham\n",
       "1917     ham\n",
       "3963    spam\n",
       "3727     ham\n",
       "25       ham\n",
       "2491     ham\n",
       "5440     ham\n",
       "807      ham\n",
       "1469    spam\n",
       "2006     ham\n",
       "3924     ham\n",
       "4600     ham\n",
       "3936     ham\n",
       "4119     ham\n",
       "3195     ham\n",
       "493      ham\n",
       "1623    spam\n",
       "2651     ham\n",
       "4905     ham\n",
       "1001     ham\n",
       "2317     ham\n",
       "4240     ham\n",
       "1951     ham\n",
       "2746     ham\n",
       "5061     ham\n",
       "972      ham\n",
       "1308    spam\n",
       "4442     ham\n",
       "3273     ham\n",
       "3708     ham\n",
       "3258     ham\n",
       "2489     ham\n",
       "3939     ham\n",
       "611     spam\n",
       "5562     ham\n",
       "4828     ham\n",
       "2811     ham\n",
       "384      ham\n",
       "3832     ham\n",
       "5102    spam\n",
       "5020     ham\n",
       "2642    spam\n",
       "1663    spam\n",
       "5496     ham\n",
       "3345     ham\n",
       "1701     ham\n",
       "16       ham\n",
       "4012    spam\n",
       "1058     ham\n",
       "640      ham\n",
       "2659     ham\n",
       "4157     ham\n",
       "3010    spam\n",
       "3213     ham\n",
       "2169     ham\n",
       "3652     ham\n",
       "2813     ham\n",
       "4651     ham\n",
       "5234     ham\n",
       "1186     ham\n",
       "4078     ham\n",
       "3335     ham\n",
       "2662     ham\n",
       "3546     ham\n",
       "5282     ham\n",
       "5077     ham\n",
       "1716     ham\n",
       "2960     ham\n",
       "2469     ham\n",
       "3664     ham\n",
       "1966     ham\n",
       "1920     ham\n",
       "3143     ham\n",
       "4968    spam\n",
       "4945     ham\n",
       "2965    spam\n",
       "585      ham\n",
       "4484     ham\n",
       "5526    spam\n",
       "36       ham\n",
       "1072    spam\n",
       "76       ham\n",
       "2238     ham\n",
       "5314    spam\n",
       "4476     ham\n",
       "997      ham\n",
       "4148     ham\n",
       "2368     ham\n",
       "625      ham\n",
       "5366    spam\n",
       "4055     ham\n",
       "2049     ham\n",
       "3403     ham\n",
       "3713     ham\n",
       "1407    spam\n",
       "1905     ham\n",
       "639      ham\n",
       "375     spam\n",
       "80       ham\n",
       "3554     ham\n",
       "2170    spam\n",
       "4538     ham\n",
       "1327     ham\n",
       "2786     ham\n",
       "2793     ham\n",
       "3293     ham\n",
       "4747     ham\n",
       "5066     ham\n",
       "5390     ham\n",
       "1384     ham\n",
       "189      ham\n",
       "1515     ham\n",
       "5350     ham\n",
       "5571     ham\n",
       "2344     ham\n",
       "4166    spam\n",
       "2059     ham\n",
       "353      ham\n",
       "2398     ham\n",
       "3081     ham\n",
       "4235     ham\n",
       "2248    spam\n",
       "4421     ham\n",
       "1383     ham\n",
       "1628    spam\n",
       "2176     ham\n",
       "3849     ham\n",
       "2495     ham\n",
       "4575     ham\n",
       "2326     ham\n",
       "4034     ham\n",
       "5337     ham\n",
       "2929     ham\n",
       "3476     ham\n",
       "4859     ham\n",
       "3106     ham\n",
       "1470     ham\n",
       "1839    spam\n",
       "5196    spam\n",
       "2110     ham\n",
       "3743     ham\n",
       "3298    spam\n",
       "240     spam\n",
       "1517     ham\n",
       "4127    spam\n",
       "2163     ham\n",
       "3334    spam\n",
       "4398     ham\n",
       "676      ham\n",
       "3702     ham\n",
       "4684     ham\n",
       "5207     ham\n",
       "4477     ham\n",
       "5119     ham\n",
       "1382     ham\n",
       "1205    spam\n",
       "2454     ham\n",
       "2919     ham\n",
       "3486     ham\n",
       "4165     ham\n",
       "1027     ham\n",
       "1019     ham\n",
       "1816     ham\n",
       "3105     ham\n",
       "4671     ham\n",
       "4849     ham\n",
       "3430     ham\n",
       "4899     ham\n",
       "2830    spam\n",
       "4455     ham\n",
       "2392     ham\n",
       "3055     ham\n",
       "1483     ham\n",
       "3928     ham\n",
       "2373     ham\n",
       "4669     ham\n",
       "3818     ham\n",
       "3913    spam\n",
       "3070     ham\n",
       "2367    spam\n",
       "3142     ham\n",
       "135     spam\n",
       "2623     ham\n",
       "1292     ham\n",
       "4718     ham\n",
       "852      ham\n",
       "2814     ham\n",
       "3150     ham\n",
       "4730     ham\n",
       "1617     ham\n",
       "2826    spam\n",
       "3413     ham\n",
       "3852     ham\n",
       "3177     ham\n",
       "2614     ham\n",
       "5164    spam\n",
       "5087     ham\n",
       "2867     ham\n",
       "3617     ham\n",
       "5072     ham\n",
       "3984     ham\n",
       "5518     ham\n",
       "3582     ham\n",
       "140      ham\n",
       "3509     ham\n",
       "1589     ham\n",
       "5031     ham\n",
       "2496    spam\n",
       "4976     ham\n",
       "2437     ham\n",
       "3279     ham\n",
       "5494     ham\n",
       "820      ham\n",
       "4741     ham\n",
       "2745     ham\n",
       "5448     ham\n",
       "3977     ham\n",
       "4663     ham\n",
       "2532     ham\n",
       "1136     ham\n",
       "1817     ham\n",
       "229      ham\n",
       "999      ham\n",
       "2715     ham\n",
       "1558     ham\n",
       "3200     ham\n",
       "5063     ham\n",
       "2580     ham\n",
       "5113     ham\n",
       "24       ham\n",
       "1118    spam\n",
       "2149     ham\n",
       "628      ham\n",
       "1471     ham\n",
       "261      ham\n",
       "3910     ham\n",
       "1388     ham\n",
       "3040     ham\n",
       "4053     ham\n",
       "2553     ham\n",
       "2422     ham\n",
       "3490     ham\n",
       "3609     ham\n",
       "1695     ham\n",
       "8       spam\n",
       "1606     ham\n",
       "1066     ham\n",
       "1902     ham\n",
       "2411     ham\n",
       "5457     ham\n",
       "1713     ham\n",
       "3061     ham\n",
       "400      ham\n",
       "4771     ham\n",
       "4993     ham\n",
       "1994     ham\n",
       "1539     ham\n",
       "5125     ham\n",
       "4616    spam\n",
       "4317     ham\n",
       "4920     ham\n",
       "3281     ham\n",
       "38       ham\n",
       "2292     ham\n",
       "4006     ham\n",
       "864      ham\n",
       "4623     ham\n",
       "5357     ham\n",
       "4740     ham\n",
       "4550     ham\n",
       "1434     ham\n",
       "2440     ham\n",
       "2433     ham\n",
       "2375     ham\n",
       "4719     ham\n",
       "4860     ham\n",
       "207      ham\n",
       "3328     ham\n",
       "3101     ham\n",
       "3362     ham\n",
       "2568     ham\n",
       "1069    spam\n",
       "4140     ham\n",
       "2096     ham\n",
       "890      ham\n",
       "669      ham\n",
       "851      ham\n",
       "4466     ham\n",
       "1654     ham\n",
       "698      ham\n",
       "5531     ham\n",
       "5560     ham\n",
       "293      ham\n",
       "5296     ham\n",
       "894      ham\n",
       "2724     ham\n",
       "1325     ham\n",
       "2297    spam\n",
       "983     spam\n",
       "3788     ham\n",
       "1112     ham\n",
       "631      ham\n",
       "1967     ham\n",
       "4352     ham\n",
       "212      ham\n",
       "5231     ham\n",
       "1609     ham\n",
       "5443    spam\n",
       "3004     ham\n",
       "3997     ham\n",
       "1287     ham\n",
       "5449    spam\n",
       "2990    spam\n",
       "5249     ham\n",
       "5148     ham\n",
       "2376     ham\n",
       "198      ham\n",
       "4246     ham\n",
       "5029     ham\n",
       "4448     ham\n",
       "4353     ham\n",
       "3781     ham\n",
       "2666     ham\n",
       "5477     ham\n",
       "1442     ham\n",
       "3569     ham\n",
       "4925     ham\n",
       "2271     ham\n",
       "2639     ham\n",
       "523      ham\n",
       "5400     ham\n",
       "5569     ham\n",
       "4781     ham\n",
       "3944     ham\n",
       "1934     ham\n",
       "3535     ham\n",
       "3699     ham\n",
       "570      ham\n",
       "5377    spam\n",
       "3141    spam\n",
       "4410    spam\n",
       "4675     ham\n",
       "3728     ham\n",
       "4831     ham\n",
       "2631     ham\n",
       "295      ham\n",
       "3423    spam\n",
       "3171     ham\n",
       "3906    spam\n",
       "2876     ham\n",
       "4197     ham\n",
       "4445     ham\n",
       "4203     ham\n",
       "5553     ham\n",
       "4647    spam\n",
       "821      ham\n",
       "3310     ham\n",
       "3297     ham\n",
       "5226     ham\n",
       "1204     ham\n",
       "4449     ham\n",
       "567      ham\n",
       "2446     ham\n",
       "3000     ham\n",
       "1664     ham\n",
       "3499     ham\n",
       "2439     ham\n",
       "3886     ham\n",
       "2939     ham\n",
       "5100     ham\n",
       "4941     ham\n",
       "4518     ham\n",
       "2085     ham\n",
       "2509     ham\n",
       "3623     ham\n",
       "2307     ham\n",
       "3828    spam\n",
       "4327     ham\n",
       "4654     ham\n",
       "1645     ham\n",
       "4496     ham\n",
       "2103     ham\n",
       "3815     ham\n",
       "4922     ham\n",
       "750      ham\n",
       "2420    spam\n",
       "1161     ham\n",
       "2596    spam\n",
       "4001    spam\n",
       "2885     ham\n",
       "2570     ham\n",
       "5424     ham\n",
       "2074    spam\n",
       "277      ham\n",
       "158      ham\n",
       "4091    spam\n",
       "4681     ham\n",
       "1146    spam\n",
       "294      ham\n",
       "2752     ham\n",
       "977      ham\n",
       "1761     ham\n",
       "3018     ham\n",
       "1168     ham\n",
       "3517     ham\n",
       "2314     ham\n",
       "3324     ham\n",
       "3545     ham\n",
       "4295    spam\n",
       "1369     ham\n",
       "904      ham\n",
       "2585     ham\n",
       "4666     ham\n",
       "4867     ham\n",
       "1314     ham\n",
       "4085     ham\n",
       "3915     ham\n",
       "1726     ham\n",
       "2357     ham\n",
       "4493     ham\n",
       "5252     ham\n",
       "4847     ham\n",
       "4463     ham\n",
       "4653     ham\n",
       "4290     ham\n",
       "1397     ham\n",
       "1244     ham\n",
       "833     spam\n",
       "149      ham\n",
       "3647     ham\n",
       "2348     ham\n",
       "4599     ham\n",
       "184      ham\n",
       "887      ham\n",
       "920      ham\n",
       "1487     ham\n",
       "2926     ham\n",
       "3634     ham\n",
       "5468    spam\n",
       "4793     ham\n",
       "672     spam\n",
       "1908     ham\n",
       "2108     ham\n",
       "2035     ham\n",
       "2231     ham\n",
       "264     spam\n",
       "3299    spam\n",
       "2504     ham\n",
       "1411     ham\n",
       "5268     ham\n",
       "3030     ham\n",
       "209      ham\n",
       "5225     ham\n",
       "2250    spam\n",
       "2395     ham\n",
       "4401     ham\n",
       "1500    spam\n",
       "2291     ham\n",
       "1084     ham\n",
       "1267     ham\n",
       "1109     ham\n",
       "3547     ham\n",
       "2749     ham\n",
       "3454     ham\n",
       "4228     ham\n",
       "2882     ham\n",
       "3437     ham\n",
       "3322     ham\n",
       "3966     ham\n",
       "809      ham\n",
       "3170     ham\n",
       "3028     ham\n",
       "2875     ham\n",
       "3254     ham\n",
       "3975     ham\n",
       "3029     ham\n",
       "5430     ham\n",
       "5149     ham\n",
       "51       ham\n",
       "5278    spam\n",
       "3154     ham\n",
       "1969     ham\n",
       "2713     ham\n",
       "1362     ham\n",
       "1514     ham\n",
       "2152     ham\n",
       "5001     ham\n",
       "112      ham\n",
       "4726     ham\n",
       "168      ham\n",
       "2322     ham\n",
       "4691     ham\n",
       "4854     ham\n",
       "2602     ham\n",
       "4498     ham\n",
       "1245     ham\n",
       "1354     ham\n",
       "3758    spam\n",
       "1157     ham\n",
       "3537     ham\n",
       "4755     ham\n",
       "3326     ham\n",
       "4284     ham\n",
       "5522     ham\n",
       "1115     ham\n",
       "2483     ham\n",
       "853      ham\n",
       "4268     ham\n",
       "5078     ham\n",
       "2258     ham\n",
       "3899     ham\n",
       "53       ham\n",
       "4061    spam\n",
       "5352     ham\n",
       "2177     ham\n",
       "5033     ham\n",
       "5086     ham\n",
       "3700     ham\n",
       "2552     ham\n",
       "4503     ham\n",
       "2841     ham\n",
       "1212     ham\n",
       "3145     ham\n",
       "4913     ham\n",
       "3848    spam\n",
       "3994     ham\n",
       "5275     ham\n",
       "3591     ham\n",
       "5254     ham\n",
       "2765     ham\n",
       "515     spam\n",
       "5082     ham\n",
       "2709     ham\n",
       "356      ham\n",
       "5071    spam\n",
       "2710     ham\n",
       "529     spam\n",
       "3320     ham\n",
       "59       ham\n",
       "948      ham\n",
       "5235     ham\n",
       "281      ham\n",
       "3348     ham\n",
       "1629     ham\n",
       "2782     ham\n",
       "4180     ham\n",
       "4291     ham\n",
       "4751     ham\n",
       "451      ham\n",
       "3575     ham\n",
       "2732     ham\n",
       "4359    spam\n",
       "1276     ham\n",
       "1283     ham\n",
       "4047    spam\n",
       "5217     ham\n",
       "1530     ham\n",
       "4033     ham\n",
       "805      ham\n",
       "5270     ham\n",
       "1529     ham\n",
       "2554     ham\n",
       "3749     ham\n",
       "4731     ham\n",
       "49       ham\n",
       "2691    spam\n",
       "3054     ham\n",
       "801     spam\n",
       "4884     ham\n",
       "1367     ham\n",
       "424     spam\n",
       "5349     ham\n",
       "0        ham\n",
       "2034     ham\n",
       "1269    spam\n",
       "176      ham\n",
       "5322     ham\n",
       "512      ham\n",
       "1286     ham\n",
       "1462     ham\n",
       "2409     ham\n",
       "4537     ham\n",
       "2384     ham\n",
       "766     spam\n",
       "1348     ham\n",
       "3785     ham\n",
       "2482     ham\n",
       "1054     ham\n",
       "5096     ham\n",
       "5197     ham\n",
       "2455     ham\n",
       "532      ham\n",
       "4906    spam\n",
       "4947     ham\n",
       "5010     ham\n",
       "380      ham\n",
       "1866     ham\n",
       "5027    spam\n",
       "3346     ham\n",
       "2681     ham\n",
       "4721     ham\n",
       "930     spam\n",
       "2626    spam\n",
       "2526     ham\n",
       "5513     ham\n",
       "5565     ham\n",
       "419      ham\n",
       "3714     ham\n",
       "1480     ham\n",
       "1059     ham\n",
       "1970    spam\n",
       "4176     ham\n",
       "73       ham\n",
       "3173     ham\n",
       "2604     ham\n",
       "2880     ham\n",
       "1252    spam\n",
       "1894     ham\n",
       "2598     ham\n",
       "1864     ham\n",
       "1461     ham\n",
       "1181     ham\n",
       "5041    spam\n",
       "488      ham\n",
       "1124     ham\n",
       "1257     ham\n",
       "1541     ham\n",
       "388      ham\n",
       "3065     ham\n",
       "3919     ham\n",
       "2211     ham\n",
       "1290     ham\n",
       "2510     ham\n",
       "2995     ham\n",
       "5312     ham\n",
       "455     spam\n",
       "815     spam\n",
       "1086     ham\n",
       "2920     ham\n",
       "2638     ham\n",
       "3130     ham\n",
       "5431     ham\n",
       "1279     ham\n",
       "1429     ham\n",
       "2777     ham\n",
       "2222     ham\n",
       "352      ham\n",
       "3719     ham\n",
       "3389     ham\n",
       "3873     ham\n",
       "2082     ham\n",
       "1203     ham\n",
       "1405     ham\n",
       "5075     ham\n",
       "1699    spam\n",
       "1705     ham\n",
       "2913     ham\n",
       "1274    spam\n",
       "2207    spam\n",
       "163      ham\n",
       "2047     ham\n",
       "4506    spam\n",
       "3280     ham\n",
       "3360    spam\n",
       "3688     ham\n",
       "5143     ham\n",
       "408      ham\n",
       "4238     ham\n",
       "4118     ham\n",
       "4744     ham\n",
       "641      ham\n",
       "4402     ham\n",
       "1343     ham\n",
       "888      ham\n",
       "1557     ham\n",
       "1085     ham\n",
       "3927     ham\n",
       "531     spam\n",
       "3008     ham\n",
       "2447     ham\n",
       "5481     ham\n",
       "2767    spam\n",
       "1671     ham\n",
       "2109    spam\n",
       "1148     ham\n",
       "3166     ham\n",
       "266      ham\n",
       "3763    spam\n",
       "5420     ham\n",
       "3736     ham\n",
       "360      ham\n",
       "1460    spam\n",
       "3421    spam\n",
       "952      ham\n",
       "2160    spam\n",
       "5465     ham\n",
       "1574    spam\n",
       "4942     ham\n",
       "3337     ham\n",
       "1842     ham\n",
       "2208     ham\n",
       "2979     ham\n",
       "3436     ham\n",
       "4630     ham\n",
       "754      ham\n",
       "1378    spam\n",
       "980      ham\n",
       "2100    spam\n",
       "286      ham\n",
       "3533     ham\n",
       "3088     ham\n",
       "1154    spam\n",
       "1511     ham\n",
       "4231     ham\n",
       "3261     ham\n",
       "4464     ham\n",
       "2191     ham\n",
       "211      ham\n",
       "3164    spam\n",
       "274      ham\n",
       "88       ham\n",
       "2798     ham\n",
       "2324     ham\n",
       "298      ham\n",
       "3674     ham\n",
       "5069     ham\n",
       "3776     ham\n",
       "4886     ham\n",
       "315      ham\n",
       "4970     ham\n",
       "2151     ham\n",
       "3288     ham\n",
       "3117     ham\n",
       "2020     ham\n",
       "4827     ham\n",
       "2974     ham\n",
       "1275     ham\n",
       "2413    spam\n",
       "528      ham\n",
       "4404     ham\n",
       "1505     ham\n",
       "3598    spam\n",
       "3681     ham\n",
       "1318    spam\n",
       "3380     ham\n",
       "3034     ham\n",
       "2380     ham\n",
       "4311    spam\n",
       "2616     ham\n",
       "1166     ham\n",
       "3471     ham\n",
       "4695     ham\n",
       "5293     ham\n",
       "2871    spam\n",
       "1222     ham\n",
       "4749     ham\n",
       "4255     ham\n",
       "1982     ham\n",
       "5180     ham\n",
       "4020    spam\n",
       "371      ham\n",
       "3482     ham\n",
       "2131     ham\n",
       "3418     ham\n",
       "3424    spam\n",
       "1538     ham\n",
       "5393     ham\n",
       "2744     ham\n",
       "1553     ham\n",
       "4335     ham\n",
       "2817     ham\n",
       "4702     ham\n",
       "618      ham\n",
       "2381     ham\n",
       "4391     ham\n",
       "4375     ham\n",
       "3524     ham\n",
       "2629     ham\n",
       "4123     ham\n",
       "4980     ham\n",
       "2766     ham\n",
       "3895    spam\n",
       "1656     ham\n",
       "969      ham\n",
       "1843     ham\n",
       "3024     ham\n",
       "3151     ham\n",
       "3386     ham\n",
       "4962     ham\n",
       "1211     ham\n",
       "5285    spam\n",
       "1428     ham\n",
       "5147    spam\n",
       "426      ham\n",
       "4094     ham\n",
       "4271     ham\n",
       "1923     ham\n",
       "3395     ham\n",
       "5259     ham\n",
       "404      ham\n",
       "491      ham\n",
       "5097     ham\n",
       "3494     ham\n",
       "824     spam\n",
       "2542     ham\n",
       "3673     ham\n",
       "2790     ham\n",
       "4617     ham\n",
       "3515     ham\n",
       "4870     ham\n",
       "5404     ham\n",
       "1788     ham\n",
       "2187     ham\n",
       "2145    spam\n",
       "4505     ham\n",
       "3246     ham\n",
       "1841     ham\n",
       "1209     ham\n",
       "974      ham\n",
       "474     spam\n",
       "3311     ham\n",
       "215      ham\n",
       "656      ham\n",
       "3235     ham\n",
       "2519     ham\n",
       "1583     ham\n",
       "4897     ham\n",
       "1130     ham\n",
       "3038     ham\n",
       "2063     ham\n",
       "4407    spam\n",
       "131      ham\n",
       "4347     ham\n",
       "3566     ham\n",
       "1341     ham\n",
       "2184     ham\n",
       "5297     ham\n",
       "594      ham\n",
       "5058     ham\n",
       "810      ham\n",
       "247      ham\n",
       "4374     ham\n",
       "29       ham\n",
       "1119     ham\n",
       "3363     ham\n",
       "2792     ham\n",
       "4243    spam\n",
       "4779     ham\n",
       "1974     ham\n",
       "633      ham\n",
       "46       ham\n",
       "4985    spam\n",
       "4794     ham\n",
       "868     spam\n",
       "1320     ham\n",
       "4911     ham\n",
       "1543     ham\n",
       "4129     ham\n",
       "3559     ham\n",
       "4217     ham\n",
       "2503     ham\n",
       "3567     ham\n",
       "3058     ham\n",
       "860      ham\n",
       "4105     ham\n",
       "2138     ham\n",
       "1984     ham\n",
       "2310     ham\n",
       "2759     ham\n",
       "2531     ham\n",
       "848      ham\n",
       "1243     ham\n",
       "4174     ham\n",
       "4270     ham\n",
       "3045     ham\n",
       "1180     ham\n",
       "3460    spam\n",
       "4330     ham\n",
       "2371     ham\n",
       "2       spam\n",
       "5422     ham\n",
       "1755     ham\n",
       "4011    spam\n",
       "1048    spam\n",
       "1418     ham\n",
       "4491     ham\n",
       "5264     ham\n",
       "862      ham\n",
       "3863     ham\n",
       "4861     ham\n",
       "2551     ham\n",
       "5504     ham\n",
       "2431     ham\n",
       "3797     ham\n",
       "310      ham\n",
       "1618     ham\n",
       "1092     ham\n",
       "1940    spam\n",
       "3825     ham\n",
       "1229    spam\n",
       "5262     ham\n",
       "1733     ham\n",
       "5549     ham\n",
       "3750    spam\n",
       "3063     ham\n",
       "2622     ham\n",
       "1393     ham\n",
       "4562     ham\n",
       "4349     ham\n",
       "2834    spam\n",
       "2405     ham\n",
       "3009    spam\n",
       "4122     ham\n",
       "762      ham\n",
       "3890     ham\n",
       "4892     ham\n",
       "966      ham\n",
       "3314     ham\n",
       "3441     ham\n",
       "682      ham\n",
       "2546     ham\n",
       "991      ham\n",
       "914      ham\n",
       "4627     ham\n",
       "4809     ham\n",
       "185      ham\n",
       "922      ham\n",
       "4868     ham\n",
       "4170     ham\n",
       "3556    spam\n",
       "1619     ham\n",
       "1830    spam\n",
       "2484     ham\n",
       "3148     ham\n",
       "740      ham\n",
       "4907     ham\n",
       "971      ham\n",
       "2564     ham\n",
       "3962     ham\n",
       "1116     ham\n",
       "156      ham\n",
       "2467     ham\n",
       "3860    spam\n",
       "831     spam\n",
       "835      ham\n",
       "2825     ham\n",
       "502      ham\n",
       "989      ham\n",
       "3937     ham\n",
       "923      ham\n",
       "2044    spam\n",
       "1980     ham\n",
       "249      ham\n",
       "3911     ham\n",
       "2683     ham\n",
       "1346     ham\n",
       "5088     ham\n",
       "4765     ham\n",
       "3653     ham\n",
       "355      ham\n",
       "744      ham\n",
       "844     spam\n",
       "723      ham\n",
       "1976     ham\n",
       "2955     ham\n",
       "4340     ham\n",
       "2214     ham\n",
       "3648     ham\n",
       "3870     ham\n",
       "4488     ham\n",
       "3292     ham\n",
       "4688     ham\n",
       "1258     ham\n",
       "2988     ham\n",
       "85       ham\n",
       "746      ham\n",
       "1867     ham\n",
       "1315     ham\n",
       "3898     ham\n",
       "962     spam\n",
       "4650     ham\n",
       "265      ham\n",
       "2428     ham\n",
       "4116     ham\n",
       "3086     ham\n",
       "3139     ham\n",
       "2069     ham\n",
       "4202     ham\n",
       "4533     ham\n",
       "1800     ham\n",
       "2235     ham\n",
       "3543     ham\n",
       "3062     ham\n",
       "2212     ham\n",
       "5419     ham\n",
       "4266     ham\n",
       "5244     ham\n",
       "1985    spam\n",
       "1371     ham\n",
       "2122     ham\n",
       "3907     ham\n",
       "5343     ham\n",
       "2057     ham\n",
       "5341     ham\n",
       "3947     ham\n",
       "2058     ham\n",
       "3711     ham\n",
       "2904     ham\n",
       "3838     ham\n",
       "4989     ham\n",
       "5512     ham\n",
       "284      ham\n",
       "95      spam\n",
       "5315     ham\n",
       "2664    spam\n",
       "3955     ham\n",
       "3442    spam\n",
       "4735    spam\n",
       "5469     ham\n",
       "2649     ham\n",
       "2280     ham\n",
       "2521     ham\n",
       "3613     ham\n",
       "1284     ham\n",
       "4022     ham\n",
       "2003    spam\n",
       "2153     ham\n",
       "3764     ham\n",
       "2239     ham\n",
       "3932     ham\n",
       "4770     ham\n",
       "4151     ham\n",
       "4578    spam\n",
       "43       ham\n",
       "3956     ham\n",
       "4416     ham\n",
       "2802     ham\n",
       "3089     ham\n",
       "5083     ham\n",
       "4991    spam\n",
       "4333     ham\n",
       "1809     ham\n",
       "1003     ham\n",
       "3859     ham\n",
       "2393     ham\n",
       "1076     ham\n",
       "4862     ham\n",
       "3855     ham\n",
       "3412     ham\n",
       "4754    spam\n",
       "300      ham\n",
       "2898     ham\n",
       "2507     ham\n",
       "942      ham\n",
       "4835     ham\n",
       "2370     ham\n",
       "1259     ham\n",
       "4838     ham\n",
       "2522     ham\n",
       "3156     ham\n",
       "4559     ham\n",
       "4101     ham\n",
       "841      ham\n",
       "1868     ham\n",
       "326      ham\n",
       "2436     ham\n",
       "3208     ham\n",
       "5169     ham\n",
       "1464     ham\n",
       "3131     ham\n",
       "2061     ham\n",
       "4483     ham\n",
       "2571     ham\n",
       "3103     ham\n",
       "3333     ham\n",
       "603      ham\n",
       "4418     ham\n",
       "865      ham\n",
       "1890     ham\n",
       "4042    spam\n",
       "5114     ham\n",
       "5046     ham\n",
       "3367     ham\n",
       "1280     ham\n",
       "830      ham\n",
       "3149     ham\n",
       "3799     ham\n",
       "1904    spam\n",
       "4551     ham\n",
       "4403     ham\n",
       "2050     ham\n",
       "1302     ham\n",
       "328      ham\n",
       "1704     ham\n",
       "2493     ham\n",
       "5509     ham\n",
       "4025     ham\n",
       "479      ham\n",
       "3629     ham\n",
       "1175     ham\n",
       "5093     ham\n",
       "2957     ham\n",
       "4010     ham\n",
       "117     spam\n",
       "2862     ham\n",
       "879     spam\n",
       "1029     ham\n",
       "466      ham\n",
       "4818     ham\n",
       "3083     ham\n",
       "1901     ham\n",
       "1975     ham\n",
       "776      ham\n",
       "4664     ham\n",
       "1786     ham\n",
       "4977     ham\n",
       "5510     ham\n",
       "84       ham\n",
       "1665     ham\n",
       "3487     ham\n",
       "2789     ham\n",
       "2143     ham\n",
       "2199     ham\n",
       "511      ham\n",
       "3209     ham\n",
       "731     spam\n",
       "2220    spam\n",
       "4893     ham\n",
       "4626     ham\n",
       "4921     ham\n",
       "2783     ham\n",
       "2002     ham\n",
       "5406     ham\n",
       "3666     ham\n",
       "5073    spam\n",
       "4470     ham\n",
       "1633     ham\n",
       "2757     ham\n",
       "2859     ham\n",
       "1184     ham\n",
       "3122     ham\n",
       "3184     ham\n",
       "2055     ham\n",
       "4334     ham\n",
       "4083     ham\n",
       "127      ham\n",
       "4450    spam\n",
       "164     spam\n",
       "5277     ham\n",
       "1510     ham\n",
       "3199     ham\n",
       "1319     ham\n",
       "2540     ham\n",
       "472      ham\n",
       "1997     ham\n",
       "18       ham\n",
       "3952     ham\n",
       "2956     ham\n",
       "2042     ham\n",
       "2137     ham\n",
       "1025     ham\n",
       "97       ham\n",
       "4990     ham\n",
       "3114     ham\n",
       "2835     ham\n",
       "3161     ham\n",
       "449      ham\n",
       "550      ham\n",
       "4372     ham\n",
       "3744     ham\n",
       "178      ham\n",
       "4529     ham\n",
       "3654     ham\n",
       "1340     ham\n",
       "5409     ham\n",
       "3548    spam\n",
       "3520     ham\n",
       "1591     ham\n",
       "1516     ham\n",
       "741      ham\n",
       "1769     ham\n",
       "5158     ham\n",
       "483      ham\n",
       "5220     ham\n",
       "2810     ham\n",
       "2021     ham\n",
       "5528     ham\n",
       "1910     ham\n",
       "2485     ham\n",
       "780      ham\n",
       "4644     ham\n",
       "77       ham\n",
       "4878     ham\n",
       "1889     ham\n",
       "5136     ham\n",
       "673     spam\n",
       "2203     ham\n",
       "4782     ham\n",
       "458      ham\n",
       "2865     ham\n",
       "752     spam\n",
       "121     spam\n",
       "3637     ham\n",
       "699      ham\n",
       "2924     ham\n",
       "4930    spam\n",
       "1492    spam\n",
       "5493     ham\n",
       "1948     ham\n",
       "2086     ham\n",
       "3365     ham\n",
       "31       ham\n",
       "2154     ham\n",
       "2758     ham\n",
       "69       ham\n",
       "1449    spam\n",
       "5391     ham\n",
       "3175     ham\n",
       "3627     ham\n",
       "3877     ham\n",
       "3959     ham\n",
       "5287     ham\n",
       "3221     ham\n",
       "3146     ham\n",
       "1531     ham\n",
       "4501     ham\n",
       "2432     ham\n",
       "4361     ham\n",
       "3574    spam\n",
       "3182     ham\n",
       "1912     ham\n",
       "504      ham\n",
       "339      ham\n",
       "4910     ham\n",
       "3580     ham\n",
       "5216     ham\n",
       "798      ham\n",
       "4840     ham\n",
       "5221     ham\n",
       "5355     ham\n",
       "61       ham\n",
       "1775     ham\n",
       "2845     ham\n",
       "5492    spam\n",
       "2460     ham\n",
       "4237    spam\n",
       "1567     ham\n",
       "4289     ham\n",
       "4742     ham\n",
       "4456     ham\n",
       "2848    spam\n",
       "1689     ham\n",
       "4153     ham\n",
       "2986     ham\n",
       "2419     ham\n",
       "4454     ham\n",
       "5260     ham\n",
       "1568     ham\n",
       "3965     ham\n",
       "2339     ham\n",
       "2094    spam\n",
       "2041     ham\n",
       "4373    spam\n",
       "2200     ham\n",
       "2272     ham\n",
       "381      ham\n",
       "3864    spam\n",
       "2412     ham\n",
       "3912     ham\n",
       "1390     ham\n",
       "5018    spam\n",
       "3914     ham\n",
       "1952     ham\n",
       "4162    spam\n",
       "2915    spam\n",
       "2342     ham\n",
       "4209     ham\n",
       "245      ham\n",
       "1439     ham\n",
       "1022    spam\n",
       "3233     ham\n",
       "411      ham\n",
       "2261    spam\n",
       "1062     ham\n",
       "4212     ham\n",
       "5460    spam\n",
       "4343     ham\n",
       "3561     ham\n",
       "665      ham\n",
       "5491     ham\n",
       "5184     ham\n",
       "4188     ham\n",
       "5501    spam\n",
       "114     spam\n",
       "3989     ham\n",
       "2302     ham\n",
       "2477     ham\n",
       "3250     ham\n",
       "118      ham\n",
       "1981     ham\n",
       "2180     ham\n",
       "162      ham\n",
       "263      ham\n",
       "4342     ham\n",
       "775      ham\n",
       "4871     ham\n",
       "4648     ham\n",
       "5053     ham\n",
       "4676    spam\n",
       "4940     ham\n",
       "4473    spam\n",
       "651      ham\n",
       "3723     ham\n",
       "5486     ham\n",
       "1170     ham\n",
       "5128     ham\n",
       "3011     ham\n",
       "5511     ham\n",
       "3874     ham\n",
       "5505     ham\n",
       "1368     ham\n",
       "897      ham\n",
       "928      ham\n",
       "4772     ham\n",
       "14       ham\n",
       "2548    spam\n",
       "967      ham\n",
       "1106     ham\n",
       "5107     ham\n",
       "4336     ham\n",
       "3968    spam\n",
       "1254     ham\n",
       "2648     ham\n",
       "2923     ham\n",
       "4780     ham\n",
       "4264     ham\n",
       "5514     ham\n",
       "1639     ham\n",
       "1133     ham\n",
       "5205    spam\n",
       "3519     ham\n",
       "1878     ham\n",
       "271      ham\n",
       "1473     ham\n",
       "1547     ham\n",
       "4310     ham\n",
       "5188     ham\n",
       "4440     ham\n",
       "838      ham\n",
       "2195     ham\n",
       "1835     ham\n",
       "4891     ham\n",
       "412      ham\n",
       "1712     ham\n",
       "4438     ham\n",
       "5043    spam\n",
       "2795     ham\n",
       "2221     ham\n",
       "377      ham\n",
       "1491     ham\n",
       "738     spam\n",
       "3377     ham\n",
       "3615     ham\n",
       "5127     ham\n",
       "52       ham\n",
       "4114     ham\n",
       "2269    spam\n",
       "3094     ham\n",
       "1389     ham\n",
       "3188     ham\n",
       "3478     ham\n",
       "3433    spam\n",
       "4191     ham\n",
       "2309    spam\n",
       "3222    spam\n",
       "2590    spam\n",
       "1632     ham\n",
       "4275     ham\n",
       "3174    spam\n",
       "4812     ham\n",
       "2976     ham\n",
       "4280    spam\n",
       "467      ham\n",
       "5317     ham\n",
       "903      ham\n",
       "5291     ham\n",
       "71       ham\n",
       "3217    spam\n",
       "1898     ham\n",
       "5052     ham\n",
       "3995     ham\n",
       "1207    spam\n",
       "2077     ham\n",
       "1590     ham\n",
       "2844     ham\n",
       "2205     ham\n",
       "2980    spam\n",
       "658      ham\n",
       "63       ham\n",
       "1838     ham\n",
       "4000     ham\n",
       "3036     ham\n",
       "454      ham\n",
       "402      ham\n",
       "5085     ham\n",
       "1472     ham\n",
       "677      ham\n",
       "3356     ham\n",
       "1616     ham\n",
       "1251     ham\n",
       "1983     ham\n",
       "3425    spam\n",
       "4918    spam\n",
       "5059     ham\n",
       "3843     ham\n",
       "4931    spam\n",
       "1033     ham\n",
       "174      ham\n",
       "939     spam\n",
       "3102     ham\n",
       "4787     ham\n",
       "2587     ham\n",
       "334      ham\n",
       "873      ham\n",
       "2853     ham\n",
       "1486     ham\n",
       "4293     ham\n",
       "296     spam\n",
       "5407     ham\n",
       "5334     ham\n",
       "3845     ham\n",
       "4218     ham\n",
       "3760     ham\n",
       "378      ham\n",
       "3110     ham\n",
       "2770    spam\n",
       "3918     ham\n",
       "4138     ham\n",
       "2210     ham\n",
       "2172     ham\n",
       "2599     ham\n",
       "2052     ham\n",
       "915      ham\n",
       "5523     ham\n",
       "5330     ham\n",
       "4707     ham\n",
       "2335     ham\n",
       "3820     ham\n",
       "956      ham\n",
       "1887    spam\n",
       "5563     ham\n",
       "3717     ham\n",
       "4027     ham\n",
       "1182     ham\n",
       "5555     ham\n",
       "5004    spam\n",
       "4602    spam\n",
       "4452     ham\n",
       "1423    spam\n",
       "5544     ham\n",
       "2400     ham\n",
       "2892     ham\n",
       "3596     ham\n",
       "1722     ham\n",
       "1667     ham\n",
       "2884     ham\n",
       "2994     ham\n",
       "4763     ham\n",
       "886      ham\n",
       "4056     ham\n",
       "5326     ham\n",
       "333     spam\n",
       "153      ham\n",
       "721      ham\n",
       "373      ham\n",
       "312     spam\n",
       "1849     ham\n",
       "1622     ham\n",
       "42      spam\n",
       "2693    spam\n",
       "5067     ham\n",
       "4618     ham\n",
       "417      ham\n",
       "4858     ham\n",
       "4753     ham\n",
       "5453     ham\n",
       "5191     ham\n",
       "704      ham\n",
       "732      ham\n",
       "944      ham\n",
       "3614     ham\n",
       "1806     ham\n",
       "1018     ham\n",
       "907     spam\n",
       "1693     ham\n",
       "2791    spam\n",
       "4368     ham\n",
       "519      ham\n",
       "814      ham\n",
       "818      ham\n",
       "3449     ham\n",
       "4830     ham\n",
       "1522     ham\n",
       "1638    spam\n",
       "5476     ham\n",
       "3557     ham\n",
       "5239     ham\n",
       "1700     ham\n",
       "3526     ham\n",
       "3734     ham\n",
       "3046     ham\n",
       "1883     ham\n",
       "2592     ham\n",
       "379      ham\n",
       "3775     ham\n",
       "4003     ham\n",
       "2251     ham\n",
       "4439     ham\n",
       "2148     ham\n",
       "3726     ham\n",
       "2144     ham\n",
       "2566     ham\n",
       "1803     ham\n",
       "3621     ham\n",
       "3967     ham\n",
       "1594    spam\n",
       "4328     ham\n",
       "4890     ham\n",
       "1706     ham\n",
       "5472     ham\n",
       "3790     ham\n",
       "1820     ham\n",
       "2562     ham\n",
       "2559     ham\n",
       "4208     ham\n",
       "5095     ham\n",
       "1582     ham\n",
       "2547     ham\n",
       "319     spam\n",
       "4321     ham\n",
       "5138     ham\n",
       "3364     ham\n",
       "1763     ham\n",
       "2843     ham\n",
       "4944     ham\n",
       "4717     ham\n",
       "5263     ham\n",
       "2141     ham\n",
       "213      ham\n",
       "4866     ham\n",
       "4433     ham\n",
       "3497     ham\n",
       "803     spam\n",
       "4132     ham\n",
       "105      ham\n",
       "4458     ham\n",
       "4946     ham\n",
       "3805     ham\n",
       "2806     ham\n",
       "4952     ham\n",
       "1465     ham\n",
       "2953     ham\n",
       "565      ham\n",
       "5552     ham\n",
       "4345     ham\n",
       "2524     ham\n",
       "1474     ham\n",
       "3236     ham\n",
       "2829     ham\n",
       "2502     ham\n",
       "317      ham\n",
       "1200     ham\n",
       "5203     ham\n",
       "2278     ham\n",
       "652      ham\n",
       "70       ham\n",
       "2658     ham\n",
       "1174     ham\n",
       "1088     ham\n",
       "5530     ham\n",
       "410      ham\n",
       "4064     ham\n",
       "5452     ham\n",
       "2386    spam\n",
       "5121     ham\n",
       "2091     ham\n",
       "4635     ham\n",
       "601      ham\n",
       "3013     ham\n",
       "4792     ham\n",
       "2219     ham\n",
       "2465     ham\n",
       "837     spam\n",
       "3325     ham\n",
       "624      ham\n",
       "1627     ham\n",
       "806      ham\n",
       "4978     ham\n",
       "3115     ham\n",
       "637      ham\n",
       "423      ham\n",
       "4823    spam\n",
       "1996     ham\n",
       "4472     ham\n",
       "4620     ham\n",
       "2486     ham\n",
       "150      ham\n",
       "3109     ham\n",
       "1580     ham\n",
       "626      ham\n",
       "3002    spam\n",
       "4601     ham\n",
       "3796     ham\n",
       "3481     ham\n",
       "143      ham\n",
       "4813     ham\n",
       "2574    spam\n",
       "4662     ham\n",
       "4014     ham\n",
       "1880    spam\n",
       "5251     ham\n",
       "3452     ham\n",
       "3605     ham\n",
       "3342     ham\n",
       "5342    spam\n",
       "2171     ham\n",
       "4975     ham\n",
       "5171     ham\n",
       "2780     ham\n",
       "4720     ham\n",
       "2832     ham\n",
       "5546     ham\n",
       "2230     ham\n",
       "617      ham\n",
       "1324     ham\n",
       "690     spam\n",
       "5389     ham\n",
       "2288     ham\n",
       "3302    spam\n",
       "1350    spam\n",
       "2729    spam\n",
       "4561     ham\n",
       "1187     ham\n",
       "1191     ham\n",
       "145      ham\n",
       "3572     ham\n",
       "4420     ham\n",
       "3742    spam\n",
       "1762     ham\n",
       "3800     ham\n",
       "4802     ham\n",
       "4810     ham\n",
       "1834     ham\n",
       "5454     ham\n",
       "1111     ham\n",
       "2127     ham\n",
       "4997     ham\n",
       "4783     ham\n",
       "2277     ham\n",
       "3795     ham\n",
       "2499     ham\n",
       "1824     ham\n",
       "2788     ham\n",
       "4196    spam\n",
       "4386    spam\n",
       "3827     ham\n",
       "2492     ham\n",
       "878     spam\n",
       "1455     ham\n",
       "391      ham\n",
       "4182     ham\n",
       "2283     ham\n",
       "2714     ham\n",
       "2958     ham\n",
       "475      ham\n",
       "1694     ham\n",
       "1295     ham\n",
       "2092     ham\n",
       "3050     ham\n",
       "1137    spam\n",
       "2072     ham\n",
       "5331     ham\n",
       "832      ham\n",
       "591     spam\n",
       "4658    spam\n",
       "3592     ham\n",
       "109      ham\n",
       "5256     ham\n",
       "4318     ham\n",
       "1052     ham\n",
       "1311     ham\n",
       "668      ham\n",
       "253      ham\n",
       "5168     ham\n",
       "2690     ham\n",
       "4641     ham\n",
       "5045     ham\n",
       "843      ham\n",
       "4159     ham\n",
       "4509     ham\n",
       "3374     ham\n",
       "3394     ham\n",
       "884      ham\n",
       "4547     ham\n",
       "5354     ham\n",
       "3996     ham\n",
       "4752    spam\n",
       "1879     ham\n",
       "1485     ham\n",
       "2417     ham\n",
       "2737     ham\n",
       "2267    spam\n",
       "4173     ham\n",
       "3368     ham\n",
       "2808    spam\n",
       "869     spam\n",
       "2468     ham\n",
       "3893    spam\n",
       "450      ham\n",
       "5115    spam\n",
       "1979     ham\n",
       "696      ham\n",
       "1741    spam\n",
       "3718     ham\n",
       "811      ham\n",
       "3284     ham\n",
       "2189    spam\n",
       "5006     ham\n",
       "5145     ham\n",
       "505     spam\n",
       "3303     ham\n",
       "405      ham\n",
       "3640     ham\n",
       "183      ham\n",
       "5459     ham\n",
       "1876    spam\n",
       "609      ham\n",
       "2674     ham\n",
       "2033     ham\n",
       "3981    spam\n",
       "1968     ham\n",
       "20       ham\n",
       "2218     ham\n",
       "2224    spam\n",
       "327      ham\n",
       "3270     ham\n",
       "2518     ham\n",
       "1874    spam\n",
       "4362     ham\n",
       "1756     ham\n",
       "2178     ham\n",
       "4961     ham\n",
       "5516     ham\n",
       "3410     ham\n",
       "5456    spam\n",
       "489      ham\n",
       "606      ham\n",
       "3212     ham\n",
       "2464     ham\n",
       "1738     ham\n",
       "152      ham\n",
       "889      ham\n",
       "5508     ham\n",
       "3082     ham\n",
       "269      ham\n",
       "96       ham\n",
       "3824     ham\n",
       "5060    spam\n",
       "3885    spam\n",
       "1799     ham\n",
       "4967    spam\n",
       "1572     ham\n",
       "4628    spam\n",
       "1067     ham\n",
       "5195     ham\n",
       "2760     ham\n",
       "715      ham\n",
       "4059     ham\n",
       "5527     ham\n",
       "4565     ham\n",
       "4660     ham\n",
       "1798     ham\n",
       "461      ham\n",
       "5373     ham\n",
       "2944     ham\n",
       "1795     ham\n",
       "1869     ham\n",
       "1345     ham\n",
       "4791     ham\n",
       "5271     ham\n",
       "5024     ham\n",
       "1214     ham\n",
       "1372     ham\n",
       "243      ham\n",
       "4039     ham\n",
       "2799     ham\n",
       "1679     ham\n",
       "3850     ham\n",
       "1312     ham\n",
       "648     spam\n",
       "3238     ham\n",
       "2643     ham\n",
       "4409     ham\n",
       "155      ham\n",
       "3428     ham\n",
       "3453     ham\n",
       "1303     ham\n",
       "1150     ham\n",
       "3047     ham\n",
       "1046     ham\n",
       "1640    spam\n",
       "1306     ham\n",
       "1927     ham\n",
       "3439     ham\n",
       "4121     ham\n",
       "2244     ham\n",
       "3136     ham\n",
       "15      spam\n",
       "3538     ham\n",
       "5417     ham\n",
       "4979     ham\n",
       "2669    spam\n",
       "1360     ham\n",
       "1844     ham\n",
       "3098     ham\n",
       "1612     ham\n",
       "497      ham\n",
       "2840     ham\n",
       "4611     ham\n",
       "5538     ham\n",
       "3633     ham\n",
       "1478     ham\n",
       "5507     ham\n",
       "1095     ham\n",
       "542      ham\n",
       "4729     ham\n",
       "4074     ham\n",
       "431      ham\n",
       "728      ham\n",
       "5384     ham\n",
       "4412     ham\n",
       "2561     ham\n",
       "1337     ham\n",
       "3606     ham\n",
       "2877     ham\n",
       "4415     ham\n",
       "1031     ham\n",
       "1110     ham\n",
       "1888    spam\n",
       "3550     ham\n",
       "1527     ham\n",
       "753      ham\n",
       "3049     ham\n",
       "2628     ham\n",
       "562      ham\n",
       "4764     ham\n",
       "3562    spam\n",
       "252      ham\n",
       "2516     ham\n",
       "2962     ham\n",
       "4453     ham\n",
       "5374     ham\n",
       "5396     ham\n",
       "1202     ham\n",
       "3462     ham\n",
       "2797     ham\n",
       "4225     ham\n",
       "144      ham\n",
       "5056     ham\n",
       "2895     ham\n",
       "2763     ham\n",
       "905      ham\n",
       "5192     ham\n",
       "3980     ham\n",
       "235     spam\n",
       "5157     ham\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Now that our algorithm has been trained using the training data set we can now make some predictions on the test data\n",
    "stored in 'testing_data' using predict(). Save your predictions into the 'predictions' variable.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that predictions have been made on our test set, we need to check the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluating our model ###\n",
    "\n",
    "Now that we have made predictions on our test set, our next goal is to evaluate how well our model is doing. There are various mechanisms for doing so, but first let's do quick recap of them.\n",
    "\n",
    "** Accuracy ** measures how often the classifier makes the correct prediction. Itâ€™s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
    "\n",
    "** Precision ** tells us what proportion of messages we classified as spam, actually were spam.\n",
    "It is a ratio of true positives(words classified as spam, and which are actually spam) to all positives(all words classified as spam, irrespective of whether that was the correct classification), in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Positives)]`\n",
    "\n",
    "** Recall(sensitivity)** tells us what proportion of messages that actually were spam were classified by us as spam.\n",
    "It is a ratio of true positives(words classified as spam, and which are actually spam) to all the words that were actually spam, in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Negatives)]`\n",
    "\n",
    "For classification problems that are skewed in their classification distributions like in our case, for example if we had a 100 text messages and only 2 were spam and the rest 98 weren't, accuracy by itself is not a very good metric. We could classify 90 messages as not spam(including the 2 that were spam but we classify them as not spam, hence they would be false negatives) and 10 as spam(all 10 false positives) and still get a reasonably good accuracy score. For such cases, precision and recall come in very handy. These two metrics can be combined to get the F1 score, which is weighted average of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using all 4 metrics to make sure our model does well. For all 4 metrics whose values can range from 0 to 1, having a score as close to 1 as possible is a good indicator of how well our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instructions:\n",
    "Compute the accuracy, precision, recall and F1 scores of your model using your test data 'y_test' and the predictions\n",
    "you made earlier stored in the 'predictions' variable.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885139985642498\n",
      "Precision score:  0.9720670391061452\n",
      "Recall score:  0.9405405405405406\n",
      "F1 score:  0.9560439560439562\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Solution\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions, average=\"binary\", pos_label=\"spam\")))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average=\"binary\", pos_label=\"spam\")))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average=\"binary\", pos_label=\"spam\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ham': 1208, 'spam': 185})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'spam': 562, 'ham': 3617})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Conclusion ###\n",
    "\n",
    "One of the major advantages that Naive Bayes has over other classification algorithms is its ability to handle an extremely large number of features. In our case, each word is treated as a feature and there are thousands of different words. Also, it performs well even with the presence of irrelevant features and is relatively unaffected by them. The other major advantage it has is its relative simplicity. Naive Bayes' works well right out of the box and tuning it's parameters is rarely ever necessary, except usually in cases where the distribution of the data is known. \n",
    "It rarely ever overfits the data. Another important advantage is that its model training and prediction times are very fast for the amount of data it can handle. All in all, Naive Bayes' really is a gem of an algorithm!\n",
    "\n",
    "Congratulations! You have succesfully designed a model that can efficiently predict if an SMS message is spam or not!\n",
    "\n",
    "Thank you for learning with us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
